Python 3.6.0 (v3.6.0:41df79263a11, Dec 22 2016, 17:23:13) 
[GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwin
Type "copyright", "credits" or "license()" for more information.
>>> WARNING: The version of Tcl/Tk (8.5.9) in use may be unstable.
Visit http://www.python.org/download/mac/tcltk/ for current information.

 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
>>> data[0]
array(['?', 'C', 'A', '8.0', '0.0', '?', 'S', '?', '0.0', '?', '?', 'G',
       '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?',
       '?', '?', '?', '?', '?', '?', 'COIL', '0.7', '610.0', '0.0', '?',
       '0', '?', '3'], 
      dtype='<U6')
>>> dataset['attributes']
[('family', ['?', 'GB', 'GK', 'GS', 'TN', 'ZA', 'ZF', 'ZH', 'ZM', 'ZS']), ('product-type', ['C', 'H', 'G']), ('steel', ['?', 'R', 'A', 'U', 'K', 'M', 'S', 'W', 'V']), ('carbon', 'REAL'), ('hardness', 'REAL'), ('temper_rolling', ['?', 'T']), ('condition', ['?', 'S', 'A', 'X']), ('formability', ['?', '1', '2', '3', '4', '5']), ('strength', 'REAL'), ('non-ageing', ['?', 'N']), ('surface-finish', ['?', 'P', 'M']), ('surface-quality', ['?', 'D', 'E', 'F', 'G']), ('enamelability', ['?', '1', '2', '3', '4', '5']), ('bc', ['?', 'Y']), ('bf', ['?', 'Y']), ('bt', ['?', 'Y']), ('bw/me', ['?', 'B', 'M']), ('bl', ['?', 'Y']), ('m', ['?', 'Y']), ('chrom', ['?', 'C']), ('phos', ['?', 'P']), ('cbond', ['?', 'Y']), ('marvi', ['?', 'Y']), ('exptl', ['?', 'Y']), ('ferro', ['?', 'Y']), ('corr', ['?', 'Y']), ('blue/bright/varn/clean', ['?', 'B', 'R', 'V', 'C']), ('lustre', ['?', 'Y']), ('jurofm', ['?', 'Y']), ('s', ['?', 'Y']), ('p', ['?', 'Y']), ('shape', ['COIL', 'SHEET']), ('thick', 'REAL'), ('width', 'REAL'), ('len', 'REAL'), ('oil', ['?', 'Y', 'N']), ('bore', ['0', '500', '600', '760']), ('packing', ['?', '1', '2', '3']), ('class', ['1', '2', '3', '4', '5', 'U'])]
>>> a = LabelEncoder().fit_transform(dataset['attributes'][0][1])
>>> a
array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
>>> b = OneHotEncoder(sparse=False).fit_transform(a.reshape(-1, 1))
>>> b
array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],
       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],
       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],
       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],
       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],
       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],
       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],
       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],
       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],
       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]])
>>> import pandas as pd
>>> testdata = pd.DataFrame({'pet': ['cat', 'dog', 'dog', 'fish'],'age': [4 , 6, 3, 3],
'salary':[4, 5, 1, 1]})
>>> a = LabelEncoder().fit_transform(testdata['pet'])
>>> a
array([0, 1, 1, 2])
>>> testdata['pet']
0     cat
1     dog
2     dog
3    fish
Name: pet, dtype: object
>>> OneHotEncoder( sparse=False ).fit_transform(a.reshape(-1,1))
array([[ 1.,  0.,  0.],
       [ 0.,  1.,  0.],
       [ 0.,  1.,  0.],
       [ 0.,  0.,  1.]])
>>> testdata = pd.DataFrame({'pet': ['cat', 'fish', 'dog', 'fish'],'age': [4 , 6, 3, 3],
'salary':[4, 5, 1, 1]})
>>> a = LabelEncoder().fit_transform(testdata['pet'])
>>> a
array([0, 2, 1, 2])
>>> OneHotEncoder( sparse=False ).fit_transform(a.reshape(-1,1))
array([[ 1.,  0.,  0.],
       [ 0.,  0.,  1.],
       [ 0.,  1.,  0.],
       [ 0.,  0.,  1.]])
>>> dataset['attributes']
[('family', ['?', 'GB', 'GK', 'GS', 'TN', 'ZA', 'ZF', 'ZH', 'ZM', 'ZS']), ('product-type', ['C', 'H', 'G']), ('steel', ['?', 'R', 'A', 'U', 'K', 'M', 'S', 'W', 'V']), ('carbon', 'REAL'), ('hardness', 'REAL'), ('temper_rolling', ['?', 'T']), ('condition', ['?', 'S', 'A', 'X']), ('formability', ['?', '1', '2', '3', '4', '5']), ('strength', 'REAL'), ('non-ageing', ['?', 'N']), ('surface-finish', ['?', 'P', 'M']), ('surface-quality', ['?', 'D', 'E', 'F', 'G']), ('enamelability', ['?', '1', '2', '3', '4', '5']), ('bc', ['?', 'Y']), ('bf', ['?', 'Y']), ('bt', ['?', 'Y']), ('bw/me', ['?', 'B', 'M']), ('bl', ['?', 'Y']), ('m', ['?', 'Y']), ('chrom', ['?', 'C']), ('phos', ['?', 'P']), ('cbond', ['?', 'Y']), ('marvi', ['?', 'Y']), ('exptl', ['?', 'Y']), ('ferro', ['?', 'Y']), ('corr', ['?', 'Y']), ('blue/bright/varn/clean', ['?', 'B', 'R', 'V', 'C']), ('lustre', ['?', 'Y']), ('jurofm', ['?', 'Y']), ('s', ['?', 'Y']), ('p', ['?', 'Y']), ('shape', ['COIL', 'SHEET']), ('thick', 'REAL'), ('width', 'REAL'), ('len', 'REAL'), ('oil', ['?', 'Y', 'N']), ('bore', ['0', '500', '600', '760']), ('packing', ['?', '1', '2', '3']), ('class', ['1', '2', '3', '4', '5', 'U'])]
>>> for i in dataset['attributes']:
	print(i)

	
('family', ['?', 'GB', 'GK', 'GS', 'TN', 'ZA', 'ZF', 'ZH', 'ZM', 'ZS'])
('product-type', ['C', 'H', 'G'])
('steel', ['?', 'R', 'A', 'U', 'K', 'M', 'S', 'W', 'V'])
('carbon', 'REAL')
('hardness', 'REAL')
('temper_rolling', ['?', 'T'])
('condition', ['?', 'S', 'A', 'X'])
('formability', ['?', '1', '2', '3', '4', '5'])
('strength', 'REAL')
('non-ageing', ['?', 'N'])
('surface-finish', ['?', 'P', 'M'])
('surface-quality', ['?', 'D', 'E', 'F', 'G'])
('enamelability', ['?', '1', '2', '3', '4', '5'])
('bc', ['?', 'Y'])
('bf', ['?', 'Y'])
('bt', ['?', 'Y'])
('bw/me', ['?', 'B', 'M'])
('bl', ['?', 'Y'])
('m', ['?', 'Y'])
('chrom', ['?', 'C'])
('phos', ['?', 'P'])
('cbond', ['?', 'Y'])
('marvi', ['?', 'Y'])
('exptl', ['?', 'Y'])
('ferro', ['?', 'Y'])
('corr', ['?', 'Y'])
('blue/bright/varn/clean', ['?', 'B', 'R', 'V', 'C'])
('lustre', ['?', 'Y'])
('jurofm', ['?', 'Y'])
('s', ['?', 'Y'])
('p', ['?', 'Y'])
('shape', ['COIL', 'SHEET'])
('thick', 'REAL')
('width', 'REAL')
('len', 'REAL')
('oil', ['?', 'Y', 'N'])
('bore', ['0', '500', '600', '760'])
('packing', ['?', '1', '2', '3'])
('class', ['1', '2', '3', '4', '5', 'U'])
>>> data[0]
array(['?', 'C', 'A', '8.0', '0.0', '?', 'S', '?', '0.0', '?', '?', 'G',
       '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?',
       '?', '?', '?', '?', '?', '?', 'COIL', '0.7', '610.0', '0.0', '?',
       '0', '?', '3'], 
      dtype='<U6')
>>> data[:, 1]
array(['C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C'], 
      dtype='<U6')
>>> type(data)
<class 'numpy.ndarray'>
>>> a = LabelEncoder().fit_transform(data[:, 0])
>>> a
array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 2, 0, 1, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 1, 0, 0,
       1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0,
       0, 2, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0,
       0, 1, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0,
       0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,
       0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 0,
       2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 1,
       0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 2, 2, 0, 0, 0, 0,
       0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 2, 0, 1, 0, 1, 0, 0, 0, 0,
       0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 2, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 1, 0,
       0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,
       0])
>>> OneHotEncoder(sparse=False).fit_transform(a.reshape(-1, 1))
array([[ 1.,  0.,  0.],
       [ 1.,  0.,  0.],
       [ 1.,  0.,  0.],
       ..., 
       [ 1.,  0.,  0.],
       [ 1.,  0.,  0.],
       [ 1.,  0.,  0.]])
>>> data[0]
array(['?', 'C', 'A', '8.0', '0.0', '?', 'S', '?', '0.0', '?', '?', 'G',
       '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?',
       '?', '?', '?', '?', '?', '?', 'COIL', '0.7', '610.0', '0.0', '?',
       '0', '?', '3'], 
      dtype='<U6')
>>> data[:, 0]
array(['?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?',
       '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?',
       '?', '?', '?', '?', 'TN', '?', '?', '?', '?', 'TN', '?', '?', '?',
       '?', 'ZS', '?', 'ZS', '?', 'TN', '?', '?', '?', '?', '?', '?', '?',
       '?', '?', '?', '?', '?', '?', '?', 'ZS', 'ZS', '?', '?', 'ZS', '?',
       '?', 'TN', '?', '?', 'TN', '?', '?', '?', '?', '?', '?', '?', '?',
       'ZS', '?', '?', '?', '?', '?', 'ZS', '?', '?', '?', '?', 'TN', '?',
       '?', '?', '?', '?', '?', '?', 'TN', 'TN', '?', '?', '?', '?', '?',
       '?', '?', '?', 'TN', '?', '?', '?', '?', 'TN', '?', '?', '?', '?',
       '?', 'ZS', '?', '?', '?', '?', '?', '?', 'TN', '?', 'TN', '?', '?',
       '?', '?', '?', '?', '?', '?', '?', '?', 'TN', '?', '?', '?', '?',
       '?', '?', 'ZS', '?', '?', '?', '?', '?', 'ZS', '?', '?', '?', '?',
       '?', '?', 'TN', 'ZS', 'TN', '?', '?', '?', '?', '?', '?', '?', '?',
       'TN', '?', '?', 'TN', '?', '?', '?', 'ZS', '?', '?', '?', '?', 'TN',
       '?', '?', '?', '?', '?', '?', 'ZS', '?', '?', 'TN', '?', '?', '?',
       '?', '?', '?', '?', '?', '?', '?', 'ZS', '?', '?', '?', '?', '?',
       '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?',
       '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?',
       'TN', '?', '?', '?', 'TN', '?', '?', '?', '?', '?', '?', '?', '?',
       '?', '?', 'ZS', '?', 'ZS', '?', '?', 'ZS', '?', '?', 'TN', 'TN',
       '?', '?', '?', '?', '?', '?', 'TN', '?', '?', '?', '?', '?', '?',
       '?', '?', '?', 'TN', '?', '?', '?', '?', '?', '?', '?', '?', '?',
       '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', 'TN',
       '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?',
       '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', 'TN',
       '?', '?', '?', '?', '?', '?', 'ZS', '?', '?', 'ZS', '?', '?', 'TN',
       '?', '?', '?', '?', '?', '?', 'ZS', '?', '?', '?', '?', '?', '?',
       '?', '?', '?', 'TN', '?', '?', '?', '?', 'ZS', '?', '?', '?', '?',
       '?', 'ZS', '?', '?', '?', '?', 'TN', '?', 'ZS', '?', 'TN', '?', '?',
       '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?',
       '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?',
       '?', '?', 'ZS', '?', '?', '?', '?', '?', '?', '?', '?', 'TN', '?',
       '?', '?', '?', '?', '?', '?', '?', '?', '?', 'ZS', '?', '?', '?',
       '?', 'ZS', '?', '?', 'ZS', '?', '?', '?', '?', '?', 'ZS', '?', '?',
       '?', '?', 'TN', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?',
       '?', '?', '?', '?', 'TN', 'TN', '?', '?', 'ZS', '?', '?', '?', '?',
       '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?',
       '?', '?', '?', '?', '?', 'TN', '?', '?', '?', '?', 'ZS', 'ZS', '?',
       '?', 'ZS', '?', '?', '?', '?', 'TN', 'ZS', '?', 'TN', '?', '?', '?',
       'ZS', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?',
       'TN', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', 'TN', '?',
       '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?',
       '?', 'ZS', 'TN', '?', '?', '?', 'TN', '?', '?', 'ZS', '?', '?', '?',
       '?', '?', '?', 'ZS', '?', '?', '?', '?', '?', 'TN', '?', 'ZS', 'ZS',
       '?', '?', '?', '?', '?', '?', 'ZS', '?', '?', '?', '?', '?', '?',
       '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?',
       '?', '?', '?', '?', '?', '?', '?', '?', 'TN', '?', 'ZS', '?', 'TN',
       '?', 'TN', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?',
       '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?',
       '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', 'TN',
       '?', '?', '?', '?', 'ZS', '?', '?', '?', '?', '?', '?', '?', '?',
       '?', '?', '?', '?', 'TN', '?', '?', '?', 'TN', 'ZS', '?', '?', '?',
       '?', '?', 'ZS', '?', '?', '?', 'TN', '?', '?', '?', '?', '?', '?',
       '?', '?', 'ZS', '?', '?', 'TN', '?', '?', '?', '?', '?', '?', 'TN',
       '?', '?', 'TN', 'ZS', '?', 'TN', '?', 'TN', '?', '?', '?', '?', '?',
       '?', '?', 'ZS', '?', '?', 'ZS', 'ZS', '?', '?', '?', '?', '?', '?',
       '?', '?', '?', '?', '?', '?', '?', '?', '?', 'TN', '?', '?', '?',
       '?', '?', '?', '?', '?', '?', '?', '?', '?', 'TN', '?', '?', 'ZS',
       '?', 'ZS', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', 'TN',
       '?', '?', '?', '?', '?', 'TN', '?', '?', '?', '?', '?', '?', '?',
       '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', 'TN', '?', '?',
       '?', '?', '?', '?', '?', '?', '?', '?', 'ZS', 'ZS', '?', 'TN', '?',
       '?', '?', 'ZS', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?',
       '?', 'TN', 'TN', '?', '?', '?', '?', 'TN', '?', '?', '?', '?', '?',
       '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?',
       '?', '?', '?', '?', '?', '?', '?', 'ZS', '?', '?', 'ZS', '?', '?',
       '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', 'ZS', '?',
       '?', '?', '?', 'ZS', '?', '?', '?', '?', '?', '?', '?', '?', '?',
       '?', 'ZS', '?', '?', '?', '?', 'TN', 'TN', '?', 'TN', '?', '?', '?',
       '?', '?'], 
      dtype='<U6')
>>> OneHotEncoder(sparse=False).fit_transform(a.reshape(-1, 1))[-6]
array([ 0.,  1.,  0.])
>>> OneHotEncoder(sparse=False).fit_transform(a.reshape(-1, 1))[-5]
array([ 1.,  0.,  0.])
>>> OneHotEncoder(sparse=False).fit_transform(a.reshape(-1, 1))[-1]
array([ 1.,  0.,  0.])
>>> len(data)
898
>>> data.shape
(898, 39)
>>> categorical.shape
(898, 32)
>>> categorical.shape[1]
32
>>> a = LabelEncoder().fit_transform(categorical[:, 0])
>>> a
array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 2, 0, 1, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 1, 0, 0,
       1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0,
       0, 2, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0,
       0, 1, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0,
       0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,
       0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 0,
       2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 1,
       0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 2, 2, 0, 0, 0, 0,
       0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 2, 0, 1, 0, 1, 0, 0, 0, 0,
       0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 2, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 1, 0,
       0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,
       0])
>>> OneHotEncoder(sparse=False).fit_transform(a.reshape(-1, 1))
array([[ 1.,  0.,  0.],
       [ 1.,  0.,  0.],
       [ 1.,  0.,  0.],
       ..., 
       [ 1.,  0.,  0.],
       [ 1.,  0.,  0.],
       [ 1.,  0.,  0.]])
>>> categorical.shape
(898, 32)
>>> categorial[0][31]
Traceback (most recent call last):
  File "<pyshell#39>", line 1, in <module>
    categorial[0][31]
NameError: name 'categorial' is not defined
>>> categorical[0][31]
'?'
>>> categorical[0][32]
Traceback (most recent call last):
  File "<pyshell#41>", line 1, in <module>
    categorical[0][32]
IndexError: index 32 is out of bounds for axis 0 with size 32
>>> for i in range(categorical.shape[1]):
	a no
KeyboardInterrupt
>>> non_categorical.shape
(898, 6)
>>> data[0]
array(['?', 'C', 'A', '8.0', '0.0', '?', 'S', '?', '0.0', '?', '?', 'G',
       '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?',
       '?', '?', '?', '?', '?', '?', 'COIL', '0.7', '610.0', '0.0', '?',
       '0', '?', '3'], 
      dtype='<U6')
>>> X
array([['?', 'C', 'A', ..., '?', '0', '?'],
       ['?', 'C', 'R', ..., '?', '0', '?'],
       ['?', 'C', 'R', ..., '?', '0', '?'],
       ..., 
       ['?', 'C', 'V', ..., '?', '0', '?'],
       ['?', 'C', 'A', ..., '?', '0', '?'],
       ['?', 'C', 'A', ..., '?', '500', '?']], 
      dtype='<U6')
>>> Y
array(['3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3',
       '3', '3', '3', 'U', 'U', '3', '3', '3', '3', 'U', '3', '1', '3',
       '3', '3', '3', '3', '5', '3', '3', 'U', '3', '5', '3', '3', '3',
       '3', '3', '3', '3', '3', '5', '3', '3', '3', '3', '3', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', 'U', '3',
       '3', '5', '2', '3', '5', '3', '3', '3', '3', '3', '3', '2', '3',
       '3', '3', '3', '3', '2', '3', '3', '3', '2', '3', '2', '5', 'U',
       '3', '3', '3', '3', '3', '2', '5', '5', '2', '2', '3', '3', '3',
       '3', '3', '3', '5', '3', '3', '3', '3', '5', '3', '3', '2', 'U',
       '3', '3', '1', '3', '3', '3', '3', '3', '5', '3', '5', '2', '2',
       '3', '3', '2', '2', '3', '2', '3', '3', '5', '3', '3', '3', '3',
       '3', '3', '3', '2', '3', '2', '3', '3', '3', '3', '3', '3', '3',
       '3', 'U', '5', '3', '5', '3', '3', '3', '3', '3', '3', '3', '3',
       '5', '3', '3', '5', '3', '2', '3', '3', '3', '3', '2', 'U', '5',
       '3', '3', '3', '3', '3', '3', '1', 'U', '3', '5', '3', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '2', '3', '3',
       '3', '2', '3', '2', '3', '3', '2', '3', '3', '3', '3', '3', '3',
       '5', '3', '3', '3', '5', '3', '3', '3', '3', '3', '3', '3', '2',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '5', '5', '3',
       '3', '2', '2', '3', '3', '5', '3', 'U', '3', '3', '3', '3', '3',
       '3', '3', '5', 'U', '2', '1', '3', '3', '2', '3', '2', '3', '3',
       '3', '3', '1', '3', '3', '2', '3', '3', '3', '3', '2', '5', '3',
       '3', '3', '3', '2', '2', '3', '3', '3', '3', '3', '2', '3', '3',
       '3', '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '5', '3',
       '3', '3', '3', '3', '3', 'U', '3', '3', '3', '3', 'U', '5', '3',
       '3', '3', '3', '1', '3', '3', '3', '3', '3', '3', '3', '3', '3',
       '3', '2', '5', '3', '3', '3', '3', 'U', '3', 'U', '3', '3', '3',
       '1', '3', 'U', '3', '3', '5', '3', 'U', '3', '5', '2', '2', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', 'U', '3', '2', '3', '3',
       '3', '3', '3', '3', '2', '2', '3', '3', '3', '2', '3', '3', '3',
       '2', '3', '2', '1', '2', '3', '2', '3', '2', 'U', '5', '3', '3',
       '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '3', '3', '3',
       'U', '3', '2', '3', '3', '3', '3', '3', '3', '3', '2', '3', '2',
       '3', '5', '3', '3', '2', '3', '3', '3', '3', '3', '3', 'U', '3',
       '2', '3', '2', '5', '5', '3', '3', '3', '2', '3', '3', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3',
       '3', '3', '3', '3', '5', '3', '3', '3', '3', '3', '3', '3', '3',
       'U', '3', '3', 'U', '3', '5', '3', '3', '5', '3', '3', '3', 'U',
       'U', '3', '2', '3', '3', '3', '3', '3', '3', '3', '3', '3', '5',
       '3', '3', '3', '3', '3', '3', '2', 'U', '3', '3', '5', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '2', '3', '3', '2', '2', '3',
       '3', '5', '2', '3', '3', '5', '3', '3', '3', '2', '3', '3', '2',
       '3', '3', '3', '3', '3', '3', '3', '3', '5', '3', '3', '3', '2',
       '3', '3', '3', '3', '3', 'U', '3', '3', '3', '3', '3', '3', '3',
       '3', '2', '3', '2', '3', '3', '3', 'U', '3', '3', '3', '3', '3',
       '3', '2', '3', '3', '3', '3', '3', '5', '3', '3', '3', '5', '3',
       '5', '3', '3', '3', 'U', '3', '3', '3', '3', '3', '3', '3', '3',
       '3', 'U', '3', '3', '2', '3', '3', '3', '3', '2', '3', '3', '3',
       '2', '3', '3', '2', '3', '3', '3', '3', '3', '2', '3', '5', '3',
       '3', '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '3', '2',
       '3', '3', '3', '5', '3', '3', '3', '5', '3', '3', '3', '3', '3',
       '2', '3', '3', '3', 'U', '5', '2', '3', '3', '3', '3', '3', '3',
       '2', '3', '3', '2', '5', '3', '2', '3', '3', '3', '3', '5', '3',
       '3', '5', '3', '3', '5', '2', '5', '3', '3', '3', '3', '3', '2',
       '3', '3', '3', '3', '3', 'U', '3', '3', '3', '3', '3', '2', '3',
       '2', '3', '3', 'U', '3', '3', '2', '3', '5', '3', '3', '3', '3',
       '2', '3', '3', '3', '3', '3', '3', '3', '5', '3', '3', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '5', '3',
       '2', '3', '3', '3', '5', '3', '3', '3', '3', '3', '2', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', '2', '5', '3', '3', '3',
       '3', '3', '3', '3', '2', '3', '3', 'U', '3', '3', '5', '2', '2',
       '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '3', '3', '3',
       '5', '5', '3', '3', '3', '3', '5', '3', '3', '3', '3', '3', '3',
       '3', '3', '3', '3', 'U', '3', '3', '3', '3', '3', '3', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '2', '3',
       '3', '3', '2', '3', '3', '3', '3', '3', '2', '3', 'U', '3', 'U',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '2', '3', '3', '3',
       '3', '3', '3', '3', '3', '5', '5', '2', '5', '2', '2', '2', 'U', 'U'], 
      dtype='<U6')
>>> len(Y)
898
>>> type(Y)
<class 'numpy.ndarray'>
>>> Y.sh'3', '3', '3', '3', '3', '3', '3', '3', '3', '2', '3', '3', '3',
KeyboardInterrupt
>>> Y.shape
(898,)
>>> Y[0]
'3'
>>> Y[0][1]
Traceback (most recent call last):
  File "<pyshell#51>", line 1, in <module>
    Y[0][1]
IndexError: string index out of range
>>> for i in dataset['attributes']:
	print(i)

	
('family', ['?', 'GB', 'GK', 'GS', 'TN', 'ZA', 'ZF', 'ZH', 'ZM', 'ZS'])
('product-type', ['C', 'H', 'G'])
('steel', ['?', 'R', 'A', 'U', 'K', 'M', 'S', 'W', 'V'])
('carbon', 'REAL')
('hardness', 'REAL')
('temper_rolling', ['?', 'T'])
('condition', ['?', 'S', 'A', 'X'])
('formability', ['?', '1', '2', '3', '4', '5'])
('strength', 'REAL')
('non-ageing', ['?', 'N'])
('surface-finish', ['?', 'P', 'M'])
('surface-quality', ['?', 'D', 'E', 'F', 'G'])
('enamelability', ['?', '1', '2', '3', '4', '5'])
('bc', ['?', 'Y'])
('bf', ['?', 'Y'])
('bt', ['?', 'Y'])
('bw/me', ['?', 'B', 'M'])
('bl', ['?', 'Y'])
('m', ['?', 'Y'])
('chrom', ['?', 'C'])
('phos', ['?', 'P'])
('cbond', ['?', 'Y'])
('marvi', ['?', 'Y'])
('exptl', ['?', 'Y'])
('ferro', ['?', 'Y'])
('corr', ['?', 'Y'])
('blue/bright/varn/clean', ['?', 'B', 'R', 'V', 'C'])
('lustre', ['?', 'Y'])
('jurofm', ['?', 'Y'])
('s', ['?', 'Y'])
('p', ['?', 'Y'])
('shape', ['COIL', 'SHEET'])
('thick', 'REAL')
('width', 'REAL')
('len', 'REAL')
('oil', ['?', 'Y', 'N'])
('bore', ['0', '500', '600', '760'])
('packing', ['?', '1', '2', '3'])
('class', ['1', '2', '3', '4', '5', 'U'])
>>> len(dataset['atributes'])
Traceback (most recent call last):
  File "<pyshell#55>", line 1, in <module>
    len(dataset['atributes'])
KeyError: 'atributes'
>>> len(dataset['attributes'])
39
>>> X[:, 6]
array(['S', 'S', 'S', '?', '?', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S',
       'S', 'S', 'S', '?', '?', 'S', '?', 'S', '?', '?', '?', '?', '?',
       '?', 'S', '?', '?', '?', 'S', 'S', '?', 'S', '?', '?', '?', 'S',
       'S', 'S', 'S', '?', 'S', '?', 'S', 'S', 'S', '?', 'S', 'S', 'S',
       'S', 'S', 'S', 'S', 'A', '?', 'S', 'S', 'S', 'S', 'S', '?', 'S',
       'S', '?', 'S', 'S', '?', '?', 'S', 'S', 'S', '?', 'S', '?', 'S',
       '?', 'S', 'S', 'S', 'S', '?', 'S', '?', 'S', 'S', '?', 'A', '?',
       'S', 'S', 'S', '?', 'S', 'S', '?', '?', 'S', 'S', '?', 'S', 'S',
       '?', 'S', 'S', '?', 'S', 'S', 'S', '?', '?', 'S', '?', '?', '?',
       'S', 'A', '?', 'S', 'S', 'S', '?', '?', '?', '?', '?', 'S', 'S',
       'S', '?', 'S', 'S', '?', 'S', 'S', '?', '?', '?', '?', 'S', 'A',
       'S', 'A', '?', 'S', '?', 'S', 'S', '?', '?', '?', 'S', 'S', 'S',
       'S', '?', '?', 'S', 'A', 'S', 'S', '?', 'S', 'S', 'S', 'S', 'S',
       '?', '?', 'S', '?', 'S', 'S', 'S', 'S', '?', 'S', 'S', '?', '?',
       'S', 'S', 'S', 'S', 'A', 'S', '?', '?', '?', '?', 'S', 'S', 'S',
       'S', 'S', 'S', 'S', 'S', 'S', 'S', '?', 'S', 'S', 'S', 'S', 'S',
       'S', 'S', '?', 'S', 'S', '?', 'S', 'S', 'S', '?', 'S', 'A', '?',
       'S', '?', 'S', '?', 'S', '?', 'S', 'S', 'S', 'S', 'S', 'S', 'S',
       'A', 'S', '?', 'S', '?', 'S', 'S', 'S', 'S', '?', 'S', 'S', 'S',
       'S', 'S', 'S', 'S', '?', '?', '?', '?', '?', '?', 'A', '?', '?',
       '?', 'S', 'S', 'S', 'S', 'A', 'S', '?', 'S', 'S', 'S', 'S', 'S',
       'S', 'S', 'A', '?', 'S', '?', 'S', 'S', 'S', 'S', '?', 'S', 'S',
       'S', '?', '?', '?', '?', 'S', 'S', '?', 'S', 'S', '?', 'A', 'S',
       'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', '?', 'S', '?', 'S',
       'S', '?', 'S', '?', 'S', 'S', 'S', 'S', 'S', 'S', '?', '?', 'S',
       '?', 'S', 'S', 'S', 'S', '?', '?', 'S', 'S', 'S', '?', '?', 'S',
       'S', '?', 'S', '?', 'S', '?', 'S', '?', 'S', 'S', 'S', 'A', 'S',
       'S', 'S', 'A', 'S', 'S', '?', 'S', '?', '?', '?', 'S', '?', 'S',
       '?', 'S', '?', 'S', 'S', '?', 'S', '?', '?', 'A', 'S', 'S', 'S',
       'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', '?', 'S', 'S', 'S', '?',
       '?', 'S', 'S', '?', 'S', 'S', '?', 'S', 'S', 'S', '?', 'S', '?',
       'S', '?', 'S', '?', '?', 'S', '?', 'S', '?', '?', 'A', 'S', 'S',
       '?', 'S', '?', '?', '?', 'S', 'S', 'A', 'S', 'S', 'S', '?', '?',
       '?', 'S', 'S', 'A', 'S', '?', 'S', 'S', '?', 'S', 'S', '?', 'S',
       'S', '?', '?', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', '?', '?',
       'S', 'S', 'S', '?', 'A', 'S', '?', '?', 'S', 'S', 'S', 'S', '?',
       'S', 'S', '?', 'S', 'S', 'S', 'S', '?', '?', 'S', '?', '?', '?',
       'S', 'S', 'S', 'S', 'S', '?', '?', '?', 'S', 'A', 'S', 'S', '?',
       '?', 'S', 'S', '?', 'S', '?', '?', 'S', '?', 'S', 'S', 'S', '?',
       '?', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'A',
       'S', 'S', 'S', '?', 'S', '?', 'S', '?', '?', 'S', '?', '?', 'S',
       'S', '?', '?', 'S', 'S', '?', 'S', 'S', '?', '?', 'S', 'S', 'S',
       'S', '?', 'S', 'S', 'S', '?', 'S', 'S', 'S', 'S', 'S', 'S', 'S',
       '?', 'S', 'S', '?', '?', 'S', '?', 'S', '?', 'S', '?', '?', '?',
       'S', 'S', 'S', '?', 'S', '?', 'A', 'S', 'S', 'S', '?', '?', 'S',
       'S', '?', 'S', '?', 'S', 'S', 'S', '?', 'S', '?', 'S', 'S', '?',
       'S', 'S', '?', 'S', 'S', 'S', 'S', 'A', 'S', 'A', '?', 'A', 'S',
       'S', '?', 'S', 'S', '?', 'S', 'S', 'S', '?', 'S', 'S', 'S', 'S',
       'S', '?', '?', 'S', 'S', '?', 'S', '?', '?', 'S', '?', 'S', 'S',
       'S', 'S', '?', 'S', 'S', 'S', '?', 'S', 'S', '?', 'S', '?', 'S',
       'S', 'S', 'S', 'S', '?', 'S', 'S', '?', 'S', 'S', 'S', 'S', '?',
       '?', '?', '?', '?', 'S', 'S', 'S', '?', '?', 'S', 'S', '?', 'S',
       'S', '?', 'S', 'A', '?', '?', '?', 'S', '?', 'A', '?', 'S', 'S',
       'S', 'S', 'S', 'S', '?', 'S', 'S', 'S', '?', 'S', 'S', '?', 'S',
       '?', '?', '?', '?', '?', 'S', '?', 'S', 'S', 'S', '?', '?', 'S',
       '?', 'A', 'S', 'S', '?', '?', '?', 'S', 'S', 'S', 'S', 'S', '?',
       '?', 'S', '?', '?', '?', '?', 'S', 'S', '?', 'S', 'S', 'S', 'S',
       'S', 'S', 'A', 'S', 'S', 'S', 'S', 'S', '?', '?', 'A', '?', '?',
       'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', '?', '?',
       'S', 'S', '?', 'S', '?', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S',
       'S', 'S', 'S', 'S', 'S', 'S', '?', 'S', 'S', 'A', 'S', '?', 'S',
       '?', 'S', 'S', 'S', 'S', 'S', 'S', '?', '?', 'S', 'A', '?', 'S',
       'S', 'S', 'S', '?', 'S', 'S', 'S', 'S', '?', 'A', 'S', 'S', '?',
       '?', 'A', 'S', 'S', 'S', 'S', 'A', '?', 'S', 'A', 'A', '?', 'S',
       '?', 'S', 'S', '?', '?', '?', '?', 'S', 'S', 'S', 'S', 'S', 'S',
       'S', '?', 'S', '?', 'A', 'S', 'S', 'S', 'S', 'S', 'S', '?', 'S',
       'S', 'S', 'S', '?', 'S', 'S', 'S', '?', 'S', 'S', '?', 'S', '?',
       '?', 'S', 'S', 'S', '?', '?', '?', 'S', 'S', 'S', 'S', 'S', 'S',
       '?', '?', 'S', 'S', '?', '?', 'A', 'S', '?', 'S', 'S', 'S', '?', '?'], 
      dtype='<U6')
>>> X[:, 6].shape
(898,)
>>> non_categorical.shape
(898, 6)
>>> for i in dataset['attributes']:
	print(i)

	
('family', ['?', 'GB', 'GK', 'GS', 'TN', 'ZA', 'ZF', 'ZH', 'ZM', 'ZS'])
('product-type', ['C', 'H', 'G'])
('steel', ['?', 'R', 'A', 'U', 'K', 'M', 'S', 'W', 'V'])
('carbon', 'REAL')
('hardness', 'REAL')
('temper_rolling', ['?', 'T'])
('condition', ['?', 'S', 'A', 'X'])
('formability', ['?', '1', '2', '3', '4', '5'])
('strength', 'REAL')
('non-ageing', ['?', 'N'])
('surface-finish', ['?', 'P', 'M'])
('surface-quality', ['?', 'D', 'E', 'F', 'G'])
('enamelability', ['?', '1', '2', '3', '4', '5'])
('bc', ['?', 'Y'])
('bf', ['?', 'Y'])
('bt', ['?', 'Y'])
('bw/me', ['?', 'B', 'M'])
('bl', ['?', 'Y'])
('m', ['?', 'Y'])
('chrom', ['?', 'C'])
('phos', ['?', 'P'])
('cbond', ['?', 'Y'])
('marvi', ['?', 'Y'])
('exptl', ['?', 'Y'])
('ferro', ['?', 'Y'])
('corr', ['?', 'Y'])
('blue/bright/varn/clean', ['?', 'B', 'R', 'V', 'C'])
('lustre', ['?', 'Y'])
('jurofm', ['?', 'Y'])
('s', ['?', 'Y'])
('p', ['?', 'Y'])
('shape', ['COIL', 'SHEET'])
('thick', 'REAL')
('width', 'REAL')
('len', 'REAL')
('oil', ['?', 'Y', 'N'])
('bore', ['0', '500', '600', '760'])
('packing', ['?', '1', '2', '3'])
('class', ['1', '2', '3', '4', '5', 'U'])
>>> data[0]
array(['?', 'C', 'A', '8.0', '0.0', '?', 'S', '?', '0.0', '?', '?', 'G',
       '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?',
       '?', '?', '?', '?', '?', '?', 'COIL', '0.7', '610.0', '0.0', '?',
       '0', '?', '3'], 
      dtype='<U6')
>>> data[:, 3]
array(['8.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '10.0', '0.0',
       '0.0', '0.0', '0.0', '55.0', '0.0', '70.0', '3.0', '0.0', '0.0',
       '0.0', '55.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '4.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '45.0', '0.0', '0.0', '0.0', '0.0',
       '10.0', '0.0', '0.0', '0.0', '55.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '6.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '4.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '45.0', '0.0', '0.0', '55.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '45.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '65.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '70.0', '0.0', '0.0', '55.0', '0.0', '0.0',
       '0.0', '55.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '65.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '6.0', '0.0', '45.0', '6.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '6.0',
       '0.0', '6.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '65.0', '0.0', '0.0', '55.0', '0.0',
       '4.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '65.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '6.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '65.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '65.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '65.0', '0.0', '0.0', '65.0', '0.0', '0.0',
       '45.0', '0.0', '0.0', '0.0', '6.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '55.0', '65.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '55.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '55.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '4.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '45.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '65.0', '55.0', '45.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '55.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '45.0', '0.0', '0.0', '0.0', '45.0', '0.0',
       '0.0', '65.0', '65.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '45.0', '6.0', '0.0', '45.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '65.0', '0.0', '0.0', '0.0', '0.0', '0.0', '45.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '55.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '6.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '8.0', '0.0', '0.0', '0.0', '0.0', '0.0', '55.0', '6.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '55.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '6.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '55.0', '0.0',
       '0.0', '0.0', '0.0', '70.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '70.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '65.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '45.0', '0.0', '0.0', '0.0', '0.0', '55.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '55.0', '0.0', '0.0', '70.0', '0.0',
       '65.0', '45.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '8.0',
       '0.0', '45.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '55.0', '0.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '45.0', '0.0', '0.0', '45.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0'], 
      dtype='<U6')
>>> a = np.array([[1, 2], [3, 4]])
>>> b = np.array([[5, 6]])
>>> np.concatenate((a, b))
array([[1, 2],
       [3, 4],
       [5, 6]])
>>> np.concatenate((a, b), axis = 0)
array([[1, 2],
       [3, 4],
       [5, 6]])
>>> np.concatenate((a, b), axis = 1)
Traceback (most recent call last):
  File "<pyshell#68>", line 1, in <module>
    np.concatenate((a, b), axis = 1)
ValueError: all the input array dimensions except for the concatenation axis must match exactly
>>> np.concatenate((a, b), axis = 0)
array([[1, 2],
       [3, 4],
       [5, 6]])
>>> np.concatenate((a, b), axis = 0)
array([[1, 2],
       [3, 4],
       [5, 6]])

>>> b = np.array([[5, 6,7]])
>>> np.concatenate((a, b), axis = 0)
Traceback (most recent call last):
  File "<pyshell#72>", line 1, in <module>
    np.concatenate((a, b), axis = 0)
ValueError: all the input array dimensions except for the concatenation axis must match exactly
>>> np.concatenate((a, b), axis = 1)
Traceback (most recent call last):
  File "<pyshell#73>", line 1, in <module>
    np.concatenate((a, b), axis = 1)
ValueError: all the input array dimensions except for the concatenation axis must match exactly
>>> non_categorical
array([['8.0', '0.0', '0.0', '0.7', '610.0', '0.0'],
       ['0.0', '0.0', '0.0', '3.2', '610.0', '0.0'],
       ['0.0', '0.0', '0.0', '0.7', '1300.0', '762.0'],
       ..., 
       ['0.0', '0.0', '0.0', '1.599', '150.0', '762.0'],
       ['0.0', '85.0', '0.0', '0.4', '20.0', '0.0'],
       ['0.0', '85.0', '0.0', '4.0', '610.0', '0.0']], 
      dtype='<U6')
>>> len(non_categorical)
898
>>> len(non_categorical[0])
6
>>> for i in range(categorical)
KeyboardInterrupt
>>> categorical
array([['?', 'C', 'A', ..., '?', '0', '?'],
       ['?', 'C', 'R', ..., '?', '0', '?'],
       ['?', 'C', 'R', ..., '?', '0', '?'],
       ..., 
       ['?', 'C', 'V', ..., '?', '0', '?'],
       ['?', 'C', 'A', ..., '?', '0', '?'],
       ['?', 'C', 'A', ..., '?', '500', '?']], 
      dtype='<U6')
>>> len(categorical)
898
>>> len(categorical[0])
32
>>> transformed_X = np.concatenate((categorical, non_categorical), axis = 1)
>>> len(non_categorical)
898
>>> len(non_categorical[0])
6
>>> transformed_X
array([['?', 'C', 'A', ..., '0.7', '610.0', '0.0'],
       ['?', 'C', 'R', ..., '3.2', '610.0', '0.0'],
       ['?', 'C', 'R', ..., '0.7', '1300.0', '762.0'],
       ..., 
       ['?', 'C', 'V', ..., '1.599', '150.0', '762.0'],
       ['?', 'C', 'A', ..., '0.4', '20.0', '0.0'],
       ['?', 'C', 'A', ..., '4.0', '610.0', '0.0']], 
      dtype='<U6')
>>> transformed_X[0]
array(['?', 'C', 'A', '?', 'S', '?', '?', '?', 'G', '?', '?', '?', '?',
       '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?',
       '?', '?', 'COIL', '?', '0', '?', '8.0', '0.0', '0.0', '0.7',
       '610.0', '0.0'], 
      dtype='<U6')
>>> categorical[0]
array(['?', 'C', 'A', '?', 'S', '?', '?', '?', 'G', '?', '?', '?', '?',
       '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?',
       '?', '?', 'COIL', '?', '0', '?'], 
      dtype='<U6')
>>> for i in range(len(categorical[0])):
	a = LabelEncoder
KeyboardInterrupt
>>> a = LabelEncoder().fit_transform(categorical[0][0])
Traceback (most recent call last):
  File "<pyshell#87>", line 1, in <module>
    a = LabelEncoder().fit_transform(categorical[0][0])
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/label.py", line 111, in fit_transform
    y = column_or_1d(y, warn=True)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py", line 614, in column_or_1d
    raise ValueError("bad input shape {0}".format(shape))
ValueError: bad input shape ()
>>> categorical[0]
array(['?', 'C', 'A', '?', 'S', '?', '?', '?', 'G', '?', '?', '?', '?',
       '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?',
       '?', '?', 'COIL', '?', '0', '?'], 
      dtype='<U6')
>>> a = LabelEncoder().fit_transform(categorical[:, 0])
>>> b = OneHotEncoder(sparse=False).fit_transform(a.reshape(-1, 1))
>>> b
array([[ 1.,  0.,  0.],
       [ 1.,  0.,  0.],
       [ 1.,  0.,  0.],
       ..., 
       [ 1.,  0.,  0.],
       [ 1.,  0.,  0.],
       [ 1.,  0.,  0.]])
>>> L = []
>>> for i in range(len(categorical[0])):
	a = LabelEncoder().fit_transform(categorical[:, i])
	b = OneHotEncoder(sparse=False).fit_transform(a.reshape(-1, 1))
	L.append(b)

	
>>> len(L)
32
>>> L[0]
array([[ 1.,  0.,  0.],
       [ 1.,  0.,  0.],
       [ 1.,  0.,  0.],
       ..., 
       [ 1.,  0.,  0.],
       [ 1.,  0.,  0.],
       [ 1.,  0.,  0.]])
>>> L[1]
array([[ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.]])
>>> 
KeyboardInterrupt
>>> data[0]
array(['?', 'C', 'A', '8.0', '0.0', '?', 'S', '?', '0.0', '?', '?', 'G',
       '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?',
       '?', '?', '?', '?', '?', '?', 'COIL', '0.7', '610.0', '0.0', '?',
       '0', '?', '3'], 
      dtype='<U6')
>>> data[1]
array(['?', 'C', 'R', '0.0', '0.0', '?', 'S', '2', '0.0', '?', '?', 'E',
       '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?',
       '?', '?', 'Y', '?', '?', '?', 'COIL', '3.2', '610.0', '0.0', '?',
       '0', '?', '3'], 
      dtype='<U6')
>>> data[2]
array(['?', 'C', 'R', '0.0', '0.0', '?', 'S', '2', '0.0', '?', '?', 'E',
       '?', '?', 'Y', '?', 'B', '?', '?', '?', '?', '?', '?', '?', '?',
       '?', '?', '?', '?', '?', '?', 'SHEET', '0.7', '1300.0', '762.0',
       '?', '0', '?', '3'], 
      dtype='<U6')
>>> attributes[]
KeyboardInterrupt
>>> dataset['attributes'][1]
('product-type', ['C', 'H', 'G'])
>>> data[:, 1]
array(['C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C',
       'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C'], 
      dtype='<U6')
>>> np.hstack((L[0], L[1]))
array([[ 1.,  0.,  0.,  1.],
       [ 1.,  0.,  0.,  1.],
       [ 1.,  0.,  0.,  1.],
       ..., 
       [ 1.,  0.,  0.,  1.],
       [ 1.,  0.,  0.,  1.],
       [ 1.,  0.,  0.,  1.]])
>>> a
array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2])
>>> O
Traceback (most recent call last):
  File "<pyshell#109>", line 1, in <module>
    O
NameError: name 'O' is not defined
>>> a= np.array()
Traceback (most recent call last):
  File "<pyshell#110>", line 1, in <module>
    a= np.array()
TypeError: Required argument 'object' (pos 1) not found
a
>>> b = np.array()
Traceback (most recent call last):
  File "<pyshell#111>", line 1, in <module>
    b = np.array()
TypeError: Required argument 'object' (pos 1) not found
>>> b = np.array([[]])
>>> b
array([], shape=(1, 0), dtype=float64)
>>> c = np.array([1,2],[2,3])
Traceback (most recent call last):
  File "<pyshell#114>", line 1, in <module>
    c = np.array([1,2],[2,3])
TypeError: data type not understood
>>> c = np.array([[1,2],[2,3]])
>>> c
array([[1, 2],
       [2, 3]])
>>> np.hstack(b,c)
Traceback (most recent call last):
  File "<pyshell#117>", line 1, in <module>
    np.hstack(b,c)
TypeError: hstack() takes 1 positional argument but 2 were given
>>> np.hstack((b,c))
Traceback (most recent call last):
  File "<pyshell#118>", line 1, in <module>
    np.hstack((b,c))
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/core/shape_base.py", line 288, in hstack
    return _nx.concatenate(arrs, 1)
ValueError: all the input array dimensions except for the concatenation axis must match exactly
>>> for i in L:
	final = np.st
KeyboardInterrupt
>>> for i in range(len(L) - 1):
	if i == 0:
	final = np.hstack((L[i], L[i + 1]))
KeyboardInterrupt
>>> final_output = np.hstack((L[0], L[1]))
>>> final_output
array([[ 1.,  0.,  0.,  1.],
       [ 1.,  0.,  0.,  1.],
       [ 1.,  0.,  0.,  1.],
       ..., 
       [ 1.,  0.,  0.,  1.],
       [ 1.,  0.,  0.,  1.],
       [ 1.,  0.,  0.,  1.]])
>>> for i in range(2, len(L)):
	final_output = np.hstack(final_output, L[i])

	
Traceback (most recent call last):
  File "<pyshell#125>", line 2, in <module>
    final_output = np.hstack(final_output, L[i])
TypeError: hstack() takes 1 positional argument but 2 were given
>>> for i in range(2, len(L)):
	final_output = np.hstack((final_output, L[i]))

	
>>> final_output
array([[ 1.,  0.,  0., ...,  0.,  0.,  1.],
       [ 1.,  0.,  0., ...,  0.,  0.,  1.],
       [ 1.,  0.,  0., ...,  0.,  0.,  1.],
       ..., 
       [ 1.,  0.,  0., ...,  0.,  0.,  1.],
       [ 1.,  0.,  0., ...,  0.,  0.,  1.],
       [ 1.,  0.,  0., ...,  0.,  0.,  1.]])
>>> len(final_output)
898
>>> len(final_output[0])
78
>>> non_categorical[0]
array(['8.0', '0.0', '0.0', '0.7', '610.0', '0.0'], 
      dtype='<U6')
>>> categorical = final_output
>>> transformed_X = np.concatenate((categorical, non_categorical), axis = 1)
>>> transformed_X[0]
array(['1.0', '0.0', '0.0', '1.0', '0.0', '1.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '0.0', '1.0', '0.0',
       '0.0', '0.0', '0.0', '1.0', '1.0', '0.0', '1.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '1.0', '1.0', '0.0',
       '1.0', '0.0', '1.0', '0.0', '1.0', '0.0', '0.0', '1.0', '0.0',
       '1.0', '1.0', '0.0', '1.0', '0.0', '1.0', '0.0', '1.0', '1.0',
       '0.0', '1.0', '0.0', '1.0', '1.0', '0.0', '0.0', '0.0', '1.0',
       '0.0', '1.0', '1.0', '1.0', '1.0', '0.0', '1.0', '0.0', '0.0',
       '1.0', '0.0', '0.0', '0.0', '0.0', '1.0', '8.0', '0.0', '0.0',
       '0.7', '610.0', '0.0'], 
      dtype='<U32')
>>> categorical
array([[ 1.,  0.,  0., ...,  0.,  0.,  1.],
       [ 1.,  0.,  0., ...,  0.,  0.,  1.],
       [ 1.,  0.,  0., ...,  0.,  0.,  1.],
       ..., 
       [ 1.,  0.,  0., ...,  0.,  0.,  1.],
       [ 1.,  0.,  0., ...,  0.,  0.,  1.],
       [ 1.,  0.,  0., ...,  0.,  0.,  1.]])
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
Traceback (most recent call last):
  File "/Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py", line 73, in <module>
    for i in raneg(len(categorial[0])):
NameError: name 'raneg' is not defined
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
Traceback (most recent call last):
  File "/Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py", line 73, in <module>
    for i in range(len(categorial[0])):
NameError: name 'categorial' is not defined
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
Traceback (most recent call last):
  File "/Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py", line 82, in <module>
    final_result = np.hstack((L[0], L[1]))
IndexError: list index out of range
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
>>> transformed_X
array([['1', '0', '0', ..., '0.7', '610.0', '0.0'],
       ['1', '0', '0', ..., '3.2', '610.0', '0.0'],
       ['1', '0', '0', ..., '0.7', '1300.0', '762.0'],
       ..., 
       ['1', '0', '0', ..., '1.599', '150.0', '762.0'],
       ['1', '0', '0', ..., '0.4', '20.0', '0.0'],
       ['1', '0', '0', ..., '4.0', '610.0', '0.0']], 
      dtype='<U11')
>>> transformed_X[0]
array(['1', '0', '0', '1', '0', '1', '0', '0', '0', '0', '0', '0', '1',
       '0', '0', '0', '1', '0', '0', '0', '0', '1', '1', '0', '1', '0',
       '0', '0', '0', '0', '1', '0', '0', '1', '1', '0', '1', '0', '1',
       '0', '1', '0', '0', '1', '0', '1', '1', '0', '1', '0', '1', '0',
       '1', '1', '0', '1', '0', '1', '1', '0', '0', '0', '1', '0', '1',
       '1', '1', '1', '0', '1', '0', '0', '1', '0', '0', '0', '0', '1',
       '8.0', '0.0', '0.0', '0.7', '610.0', '0.0'], 
      dtype='<U11')
>>> 
>>> array(['1.0', '0.0', '0.0', '1.0', '0.0', '1.0', '0.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '0.0', '1.0', '0.0',
       '0.0', '0.0', '0.0', '1.0', '1.0', '0.0', '1.0', '0.0', '0.0',
       '0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '1.0', '1.0', '0.0',
       '1.0', '0.0', '1.0', '0.0', '1.0', '0.0', '0.0', '1.0', '0.0',
       '1.0', '1.0', '0.0', '1.0', '0.0', '1.0', '0.0', '1.0', '1.0',
       '0.0', '1.0', '0.0', '1.0', '1.0', '0.0', '0.0', '0.0', '1.0',
       '0.0', '1.0', '1.0', '1.0', '1.0', '0.0', '1.0', '0.0', '0.0',
       '1.0', '0.0', '0.0', '0.0', '0.0', '1.0', '8.0', '0.0', '0.0',
       '0.7', '610.0', '0.0'], 
      dtype='<U32')
KeyboardInterrupt
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
Traceback (most recent call last):
  File "/Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py", line 99, in <module>
    Y = np.array([Y], dtype = np.int)
ValueError: invalid literal for int() with base 10: 'U'
>>> Y
array(['3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3',
       '3', '3', '3', 'U', 'U', '3', '3', '3', '3', 'U', '3', '1', '3',
       '3', '3', '3', '3', '5', '3', '3', 'U', '3', '5', '3', '3', '3',
       '3', '3', '3', '3', '3', '5', '3', '3', '3', '3', '3', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', 'U', '3',
       '3', '5', '2', '3', '5', '3', '3', '3', '3', '3', '3', '2', '3',
       '3', '3', '3', '3', '2', '3', '3', '3', '2', '3', '2', '5', 'U',
       '3', '3', '3', '3', '3', '2', '5', '5', '2', '2', '3', '3', '3',
       '3', '3', '3', '5', '3', '3', '3', '3', '5', '3', '3', '2', 'U',
       '3', '3', '1', '3', '3', '3', '3', '3', '5', '3', '5', '2', '2',
       '3', '3', '2', '2', '3', '2', '3', '3', '5', '3', '3', '3', '3',
       '3', '3', '3', '2', '3', '2', '3', '3', '3', '3', '3', '3', '3',
       '3', 'U', '5', '3', '5', '3', '3', '3', '3', '3', '3', '3', '3',
       '5', '3', '3', '5', '3', '2', '3', '3', '3', '3', '2', 'U', '5',
       '3', '3', '3', '3', '3', '3', '1', 'U', '3', '5', '3', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '2', '3', '3',
       '3', '2', '3', '2', '3', '3', '2', '3', '3', '3', '3', '3', '3',
       '5', '3', '3', '3', '5', '3', '3', '3', '3', '3', '3', '3', '2',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '5', '5', '3',
       '3', '2', '2', '3', '3', '5', '3', 'U', '3', '3', '3', '3', '3',
       '3', '3', '5', 'U', '2', '1', '3', '3', '2', '3', '2', '3', '3',
       '3', '3', '1', '3', '3', '2', '3', '3', '3', '3', '2', '5', '3',
       '3', '3', '3', '2', '2', '3', '3', '3', '3', '3', '2', '3', '3',
       '3', '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '5', '3',
       '3', '3', '3', '3', '3', 'U', '3', '3', '3', '3', 'U', '5', '3',
       '3', '3', '3', '1', '3', '3', '3', '3', '3', '3', '3', '3', '3',
       '3', '2', '5', '3', '3', '3', '3', 'U', '3', 'U', '3', '3', '3',
       '1', '3', 'U', '3', '3', '5', '3', 'U', '3', '5', '2', '2', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', 'U', '3', '2', '3', '3',
       '3', '3', '3', '3', '2', '2', '3', '3', '3', '2', '3', '3', '3',
       '2', '3', '2', '1', '2', '3', '2', '3', '2', 'U', '5', '3', '3',
       '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '3', '3', '3',
       'U', '3', '2', '3', '3', '3', '3', '3', '3', '3', '2', '3', '2',
       '3', '5', '3', '3', '2', '3', '3', '3', '3', '3', '3', 'U', '3',
       '2', '3', '2', '5', '5', '3', '3', '3', '2', '3', '3', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3',
       '3', '3', '3', '3', '5', '3', '3', '3', '3', '3', '3', '3', '3',
       'U', '3', '3', 'U', '3', '5', '3', '3', '5', '3', '3', '3', 'U',
       'U', '3', '2', '3', '3', '3', '3', '3', '3', '3', '3', '3', '5',
       '3', '3', '3', '3', '3', '3', '2', 'U', '3', '3', '5', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '2', '3', '3', '2', '2', '3',
       '3', '5', '2', '3', '3', '5', '3', '3', '3', '2', '3', '3', '2',
       '3', '3', '3', '3', '3', '3', '3', '3', '5', '3', '3', '3', '2',
       '3', '3', '3', '3', '3', 'U', '3', '3', '3', '3', '3', '3', '3',
       '3', '2', '3', '2', '3', '3', '3', 'U', '3', '3', '3', '3', '3',
       '3', '2', '3', '3', '3', '3', '3', '5', '3', '3', '3', '5', '3',
       '5', '3', '3', '3', 'U', '3', '3', '3', '3', '3', '3', '3', '3',
       '3', 'U', '3', '3', '2', '3', '3', '3', '3', '2', '3', '3', '3',
       '2', '3', '3', '2', '3', '3', '3', '3', '3', '2', '3', '5', '3',
       '3', '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '3', '2',
       '3', '3', '3', '5', '3', '3', '3', '5', '3', '3', '3', '3', '3',
       '2', '3', '3', '3', 'U', '5', '2', '3', '3', '3', '3', '3', '3',
       '2', '3', '3', '2', '5', '3', '2', '3', '3', '3', '3', '5', '3',
       '3', '5', '3', '3', '5', '2', '5', '3', '3', '3', '3', '3', '2',
       '3', '3', '3', '3', '3', 'U', '3', '3', '3', '3', '3', '2', '3',
       '2', '3', '3', 'U', '3', '3', '2', '3', '5', '3', '3', '3', '3',
       '2', '3', '3', '3', '3', '3', '3', '3', '5', '3', '3', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '5', '3',
       '2', '3', '3', '3', '5', '3', '3', '3', '3', '3', '2', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', '2', '5', '3', '3', '3',
       '3', '3', '3', '3', '2', '3', '3', 'U', '3', '3', '5', '2', '2',
       '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '3', '3', '3',
       '5', '5', '3', '3', '3', '3', '5', '3', '3', '3', '3', '3', '3',
       '3', '3', '3', '3', 'U', '3', '3', '3', '3', '3', '3', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '2', '3',
       '3', '3', '2', '3', '3', '3', '3', '3', '2', '3', 'U', '3', 'U',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '2', '3', '3', '3',
       '3', '3', '3', '3', '3', '5', '5', '2', '5', '2', '2', '2', 'U', 'U'], 
      dtype='<U6')
>>> I = np.array
KeyboardInterrupt
>>> Y = [1,2,3]
>>> I = np.array([I], dtype = np.int)
Traceback (most recent call last):
  File "<pyshell#141>", line 1, in <module>
    I = np.array([I], dtype = np.int)
NameError: name 'I' is not defined
>>> Y = [1,2,3]
>>> Y = np.array([I], dtype = np.int)
Traceback (most recent call last):
  File "<pyshell#143>", line 1, in <module>
    Y = np.array([I], dtype = np.int)
NameError: name 'I' is not defined
>>> Y = [1,2,3]
>>> I = np.array([Y], dtype = np.int)
>>> I
array([[1, 2, 3]])
>>> Y
[1, 2, 3]
>>> np.concatenate((transformed_X, Y.T), axis = 1)
Traceback (most recent call last):
  File "<pyshell#148>", line 1, in <module>
    np.concatenate((transformed_X, Y.T), axis = 1)
AttributeError: 'list' object has no attribute 'T'
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
Traceback (most recent call last):
  File "/Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py", line 99, in <module>
    Y = np.array([Y], dtype = np.int)
ValueError: invalid literal for int() with base 10: 'U'
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
>>> Y
array(['3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3',
       '3', '3', '3', 'U', 'U', '3', '3', '3', '3', 'U', '3', '1', '3',
       '3', '3', '3', '3', '5', '3', '3', 'U', '3', '5', '3', '3', '3',
       '3', '3', '3', '3', '3', '5', '3', '3', '3', '3', '3', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', 'U', '3',
       '3', '5', '2', '3', '5', '3', '3', '3', '3', '3', '3', '2', '3',
       '3', '3', '3', '3', '2', '3', '3', '3', '2', '3', '2', '5', 'U',
       '3', '3', '3', '3', '3', '2', '5', '5', '2', '2', '3', '3', '3',
       '3', '3', '3', '5', '3', '3', '3', '3', '5', '3', '3', '2', 'U',
       '3', '3', '1', '3', '3', '3', '3', '3', '5', '3', '5', '2', '2',
       '3', '3', '2', '2', '3', '2', '3', '3', '5', '3', '3', '3', '3',
       '3', '3', '3', '2', '3', '2', '3', '3', '3', '3', '3', '3', '3',
       '3', 'U', '5', '3', '5', '3', '3', '3', '3', '3', '3', '3', '3',
       '5', '3', '3', '5', '3', '2', '3', '3', '3', '3', '2', 'U', '5',
       '3', '3', '3', '3', '3', '3', '1', 'U', '3', '5', '3', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '2', '3', '3',
       '3', '2', '3', '2', '3', '3', '2', '3', '3', '3', '3', '3', '3',
       '5', '3', '3', '3', '5', '3', '3', '3', '3', '3', '3', '3', '2',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '5', '5', '3',
       '3', '2', '2', '3', '3', '5', '3', 'U', '3', '3', '3', '3', '3',
       '3', '3', '5', 'U', '2', '1', '3', '3', '2', '3', '2', '3', '3',
       '3', '3', '1', '3', '3', '2', '3', '3', '3', '3', '2', '5', '3',
       '3', '3', '3', '2', '2', '3', '3', '3', '3', '3', '2', '3', '3',
       '3', '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '5', '3',
       '3', '3', '3', '3', '3', 'U', '3', '3', '3', '3', 'U', '5', '3',
       '3', '3', '3', '1', '3', '3', '3', '3', '3', '3', '3', '3', '3',
       '3', '2', '5', '3', '3', '3', '3', 'U', '3', 'U', '3', '3', '3',
       '1', '3', 'U', '3', '3', '5', '3', 'U', '3', '5', '2', '2', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', 'U', '3', '2', '3', '3',
       '3', '3', '3', '3', '2', '2', '3', '3', '3', '2', '3', '3', '3',
       '2', '3', '2', '1', '2', '3', '2', '3', '2', 'U', '5', '3', '3',
       '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '3', '3', '3',
       'U', '3', '2', '3', '3', '3', '3', '3', '3', '3', '2', '3', '2',
       '3', '5', '3', '3', '2', '3', '3', '3', '3', '3', '3', 'U', '3',
       '2', '3', '2', '5', '5', '3', '3', '3', '2', '3', '3', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3',
       '3', '3', '3', '3', '5', '3', '3', '3', '3', '3', '3', '3', '3',
       'U', '3', '3', 'U', '3', '5', '3', '3', '5', '3', '3', '3', 'U',
       'U', '3', '2', '3', '3', '3', '3', '3', '3', '3', '3', '3', '5',
       '3', '3', '3', '3', '3', '3', '2', 'U', '3', '3', '5', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '2', '3', '3', '2', '2', '3',
       '3', '5', '2', '3', '3', '5', '3', '3', '3', '2', '3', '3', '2',
       '3', '3', '3', '3', '3', '3', '3', '3', '5', '3', '3', '3', '2',
       '3', '3', '3', '3', '3', 'U', '3', '3', '3', '3', '3', '3', '3',
       '3', '2', '3', '2', '3', '3', '3', 'U', '3', '3', '3', '3', '3',
       '3', '2', '3', '3', '3', '3', '3', '5', '3', '3', '3', '5', '3',
       '5', '3', '3', '3', 'U', '3', '3', '3', '3', '3', '3', '3', '3',
       '3', 'U', '3', '3', '2', '3', '3', '3', '3', '2', '3', '3', '3',
       '2', '3', '3', '2', '3', '3', '3', '3', '3', '2', '3', '5', '3',
       '3', '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '3', '2',
       '3', '3', '3', '5', '3', '3', '3', '5', '3', '3', '3', '3', '3',
       '2', '3', '3', '3', 'U', '5', '2', '3', '3', '3', '3', '3', '3',
       '2', '3', '3', '2', '5', '3', '2', '3', '3', '3', '3', '5', '3',
       '3', '5', '3', '3', '5', '2', '5', '3', '3', '3', '3', '3', '2',
       '3', '3', '3', '3', '3', 'U', '3', '3', '3', '3', '3', '2', '3',
       '2', '3', '3', 'U', '3', '3', '2', '3', '5', '3', '3', '3', '3',
       '2', '3', '3', '3', '3', '3', '3', '3', '5', '3', '3', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '5', '3',
       '2', '3', '3', '3', '5', '3', '3', '3', '3', '3', '2', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', '2', '5', '3', '3', '3',
       '3', '3', '3', '3', '2', '3', '3', 'U', '3', '3', '5', '2', '2',
       '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '3', '3', '3',
       '5', '5', '3', '3', '3', '3', '5', '3', '3', '3', '3', '3', '3',
       '3', '3', '3', '3', 'U', '3', '3', '3', '3', '3', '3', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '2', '3',
       '3', '3', '2', '3', '3', '3', '3', '3', '2', '3', 'U', '3', 'U',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '2', '3', '3', '3',
       '3', '3', '3', '3', '3', '5', '5', '2', '5', '2', '2', '2', 'U', 'U'], 
      dtype='<U6')
>>> type(Y)
<class 'numpy.ndarray'>
>>> Y = np.array([Y])
>>> Y = np.array([Y], dtype = np.int)
Traceback (most recent call last):
  File "<pyshell#152>", line 1, in <module>
    Y = np.array([Y], dtype = np.int)
ValueError: invalid literal for int() with base 10: 'U'
>>> a = LabelEncoder().fit_transform(Y)
Traceback (most recent call last):
  File "<pyshell#153>", line 1, in <module>
    a = LabelEncoder().fit_transform(Y)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/label.py", line 111, in fit_transform
    y = column_or_1d(y, warn=True)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py", line 614, in column_or_1d
    raise ValueError("bad input shape {0}".format(shape))
aValueError: bad input shape (1, 898)
>>> a
array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2])
>>> Y.reshape(-1, 1)
array([['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['U'],
       ['U'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['U'],
       ['3'],
       ['1'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['U'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['U'],
       ['3'],
       ['3'],
       ['5'],
       ['2'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['2'],
       ['5'],
       ['U'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['5'],
       ['5'],
       ['2'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['2'],
       ['U'],
       ['3'],
       ['3'],
       ['1'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['5'],
       ['3'],
       ['5'],
       ['2'],
       ['2'],
       ['3'],
       ['3'],
       ['2'],
       ['2'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['U'],
       ['5'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['5'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['U'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['1'],
       ['U'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['5'],
       ['5'],
       ['3'],
       ['3'],
       ['2'],
       ['2'],
       ['3'],
       ['3'],
       ['5'],
       ['3'],
       ['U'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['5'],
       ['U'],
       ['2'],
       ['1'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['1'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['U'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['U'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['1'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['U'],
       ['3'],
       ['U'],
       ['3'],
       ['3'],
       ['3'],
       ['1'],
       ['3'],
       ['U'],
       ['3'],
       ['3'],
       ['5'],
       ['3'],
       ['U'],
       ['3'],
       ['5'],
       ['2'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['U'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['2'],
       ['1'],
       ['2'],
       ['3'],
       ['2'],
       ['3'],
       ['2'],
       ['U'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['U'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['2'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['U'],
       ['3'],
       ['2'],
       ['3'],
       ['2'],
       ['5'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['U'],
       ['3'],
       ['3'],
       ['U'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['U'],
       ['U'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['U'],
       ['3'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['2'],
       ['2'],
       ['3'],
       ['3'],
       ['5'],
       ['2'],
       ['3'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['U'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['U'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['5'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['U'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['U'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['U'],
       ['5'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['2'],
       ['5'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['5'],
       ['2'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['U'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['U'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['5'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['U'],
       ['3'],
       ['3'],
       ['5'],
       ['2'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['5'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['5'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['U'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['U'],
       ['3'],
       ['U'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['2'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['3'],
       ['5'],
       ['5'],
       ['2'],
       ['5'],
       ['2'],
       ['2'],
       ['2'],
       ['U'],
       ['U']], 
      dtype='<U6')
>>> a = LabelEncoder().fit_transform(Y.reshape(-1, 1))

Warning (from warnings module):
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/label.py", line 111
    y = column_or_1d(y, warn=True)
DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
>>> a = LabelEncoder().fit_transform([0,1,2])
>>> a
array([0, 1, 2])
>>> len(Y)
1
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
>>> Y
array(['3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3',
       '3', '3', '3', 'U', 'U', '3', '3', '3', '3', 'U', '3', '1', '3',
       '3', '3', '3', '3', '5', '3', '3', 'U', '3', '5', '3', '3', '3',
       '3', '3', '3', '3', '3', '5', '3', '3', '3', '3', '3', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', 'U', '3',
       '3', '5', '2', '3', '5', '3', '3', '3', '3', '3', '3', '2', '3',
       '3', '3', '3', '3', '2', '3', '3', '3', '2', '3', '2', '5', 'U',
       '3', '3', '3', '3', '3', '2', '5', '5', '2', '2', '3', '3', '3',
       '3', '3', '3', '5', '3', '3', '3', '3', '5', '3', '3', '2', 'U',
       '3', '3', '1', '3', '3', '3', '3', '3', '5', '3', '5', '2', '2',
       '3', '3', '2', '2', '3', '2', '3', '3', '5', '3', '3', '3', '3',
       '3', '3', '3', '2', '3', '2', '3', '3', '3', '3', '3', '3', '3',
       '3', 'U', '5', '3', '5', '3', '3', '3', '3', '3', '3', '3', '3',
       '5', '3', '3', '5', '3', '2', '3', '3', '3', '3', '2', 'U', '5',
       '3', '3', '3', '3', '3', '3', '1', 'U', '3', '5', '3', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '2', '3', '3',
       '3', '2', '3', '2', '3', '3', '2', '3', '3', '3', '3', '3', '3',
       '5', '3', '3', '3', '5', '3', '3', '3', '3', '3', '3', '3', '2',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '5', '5', '3',
       '3', '2', '2', '3', '3', '5', '3', 'U', '3', '3', '3', '3', '3',
       '3', '3', '5', 'U', '2', '1', '3', '3', '2', '3', '2', '3', '3',
       '3', '3', '1', '3', '3', '2', '3', '3', '3', '3', '2', '5', '3',
       '3', '3', '3', '2', '2', '3', '3', '3', '3', '3', '2', '3', '3',
       '3', '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '5', '3',
       '3', '3', '3', '3', '3', 'U', '3', '3', '3', '3', 'U', '5', '3',
       '3', '3', '3', '1', '3', '3', '3', '3', '3', '3', '3', '3', '3',
       '3', '2', '5', '3', '3', '3', '3', 'U', '3', 'U', '3', '3', '3',
       '1', '3', 'U', '3', '3', '5', '3', 'U', '3', '5', '2', '2', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', 'U', '3', '2', '3', '3',
       '3', '3', '3', '3', '2', '2', '3', '3', '3', '2', '3', '3', '3',
       '2', '3', '2', '1', '2', '3', '2', '3', '2', 'U', '5', '3', '3',
       '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '3', '3', '3',
       'U', '3', '2', '3', '3', '3', '3', '3', '3', '3', '2', '3', '2',
       '3', '5', '3', '3', '2', '3', '3', '3', '3', '3', '3', 'U', '3',
       '2', '3', '2', '5', '5', '3', '3', '3', '2', '3', '3', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3',
       '3', '3', '3', '3', '5', '3', '3', '3', '3', '3', '3', '3', '3',
       'U', '3', '3', 'U', '3', '5', '3', '3', '5', '3', '3', '3', 'U',
       'U', '3', '2', '3', '3', '3', '3', '3', '3', '3', '3', '3', '5',
       '3', '3', '3', '3', '3', '3', '2', 'U', '3', '3', '5', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '2', '3', '3', '2', '2', '3',
       '3', '5', '2', '3', '3', '5', '3', '3', '3', '2', '3', '3', '2',
       '3', '3', '3', '3', '3', '3', '3', '3', '5', '3', '3', '3', '2',
       '3', '3', '3', '3', '3', 'U', '3', '3', '3', '3', '3', '3', '3',
       '3', '2', '3', '2', '3', '3', '3', 'U', '3', '3', '3', '3', '3',
       '3', '2', '3', '3', '3', '3', '3', '5', '3', '3', '3', '5', '3',
       '5', '3', '3', '3', 'U', '3', '3', '3', '3', '3', '3', '3', '3',
       '3', 'U', '3', '3', '2', '3', '3', '3', '3', '2', '3', '3', '3',
       '2', '3', '3', '2', '3', '3', '3', '3', '3', '2', '3', '5', '3',
       '3', '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '3', '2',
       '3', '3', '3', '5', '3', '3', '3', '5', '3', '3', '3', '3', '3',
       '2', '3', '3', '3', 'U', '5', '2', '3', '3', '3', '3', '3', '3',
       '2', '3', '3', '2', '5', '3', '2', '3', '3', '3', '3', '5', '3',
       '3', '5', '3', '3', '5', '2', '5', '3', '3', '3', '3', '3', '2',
       '3', '3', '3', '3', '3', 'U', '3', '3', '3', '3', '3', '2', '3',
       '2', '3', '3', 'U', '3', '3', '2', '3', '5', '3', '3', '3', '3',
       '2', '3', '3', '3', '3', '3', '3', '3', '5', '3', '3', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '5', '3',
       '2', '3', '3', '3', '5', '3', '3', '3', '3', '3', '2', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', '2', '5', '3', '3', '3',
       '3', '3', '3', '3', '2', '3', '3', 'U', '3', '3', '5', '2', '2',
       '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '3', '3', '3',
       '5', '5', '3', '3', '3', '3', '5', '3', '3', '3', '3', '3', '3',
       '3', '3', '3', '3', 'U', '3', '3', '3', '3', '3', '3', '3', '3',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '2', '3',
       '3', '3', '2', '3', '3', '3', '3', '3', '2', '3', 'U', '3', 'U',
       '3', '3', '3', '3', '3', '3', '3', '3', '3', '2', '3', '3', '3',
       '3', '3', '3', '3', '3', '5', '5', '2', '5', '2', '2', '2', 'U', 'U'], 
      dtype='<U6')
>>> Y[0]
'3'
>>> a = LabelEncoder().fit_transform(Y)
>>> a
array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 4,
       2, 0, 2, 2, 2, 2, 2, 3, 2, 2, 4, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 3, 1, 2,
       3, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 3, 4, 2,
       2, 2, 2, 2, 1, 3, 3, 1, 1, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 3, 2, 2,
       1, 4, 2, 2, 0, 2, 2, 2, 2, 2, 3, 2, 3, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2,
       3, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 4, 3, 2, 3,
       2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 1, 2, 2, 2, 2, 1, 4, 3, 2, 2,
       2, 2, 2, 2, 0, 4, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2,
       2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 3, 3, 2, 2, 1, 1, 2, 2, 3, 2, 4, 2, 2, 2, 2, 2, 2, 2, 3,
       4, 1, 0, 2, 2, 1, 2, 1, 2, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 1, 3, 2,
       2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,
       2, 3, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 3, 2, 2, 2, 2, 0, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 1, 3, 2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 0, 2, 4, 2,
       2, 3, 2, 4, 2, 3, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 1, 2, 2, 2,
       2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 0, 1, 2, 1, 2, 1, 4, 3,
       2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 4, 2, 1, 2, 2, 2, 2, 2,
       2, 2, 1, 2, 1, 2, 3, 2, 2, 1, 2, 2, 2, 2, 2, 2, 4, 2, 1, 2, 1, 3, 3,
       2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 2, 3, 2, 2, 3, 2, 2, 2,
       4, 4, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 1, 4, 2,
       2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 3, 1, 2, 2, 3,
       2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 1, 2, 2, 2,
       2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 4, 2, 2, 2, 2, 2,
       2, 1, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 3, 2, 2, 2, 4, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 4, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2,
       2, 2, 1, 2, 3, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 3,
       2, 2, 2, 3, 2, 2, 2, 2, 2, 1, 2, 2, 2, 4, 3, 1, 2, 2, 2, 2, 2, 2, 1,
       2, 2, 1, 3, 2, 1, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 3, 1, 3, 2, 2, 2, 2,
       2, 1, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 4, 2, 2, 1, 2,
       3, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 3, 2, 1, 2, 2, 2, 3, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 1, 3, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 4, 2, 2, 3, 1,
       1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 3, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 4, 2, 4, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 1, 3, 1, 1, 1, 4,
       4])
>>> dataset['attributes'][-1]
('class', ['1', '2', '3', '4', '5', 'U'])
>>> Y[-10:]
array(['3', '5', '5', '2', '5', '2', '2', '2', 'U', 'U'], 
      dtype='<U6')
>>> set(Y)
{'2', '1', '3', '5', 'U'}
>>> a = LabelEncoder().fit_transform(Y)
>>> a
array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 4,
       2, 0, 2, 2, 2, 2, 2, 3, 2, 2, 4, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 3, 1, 2,
       3, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 3, 4, 2,
       2, 2, 2, 2, 1, 3, 3, 1, 1, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 3, 2, 2,
       1, 4, 2, 2, 0, 2, 2, 2, 2, 2, 3, 2, 3, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2,
       3, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 4, 3, 2, 3,
       2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 1, 2, 2, 2, 2, 1, 4, 3, 2, 2,
       2, 2, 2, 2, 0, 4, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2,
       2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 3, 3, 2, 2, 1, 1, 2, 2, 3, 2, 4, 2, 2, 2, 2, 2, 2, 2, 3,
       4, 1, 0, 2, 2, 1, 2, 1, 2, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 1, 3, 2,
       2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,
       2, 3, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 3, 2, 2, 2, 2, 0, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 1, 3, 2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 0, 2, 4, 2,
       2, 3, 2, 4, 2, 3, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 1, 2, 2, 2,
       2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 0, 1, 2, 1, 2, 1, 4, 3,
       2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 4, 2, 1, 2, 2, 2, 2, 2,
       2, 2, 1, 2, 1, 2, 3, 2, 2, 1, 2, 2, 2, 2, 2, 2, 4, 2, 1, 2, 1, 3, 3,
       2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 2, 3, 2, 2, 3, 2, 2, 2,
       4, 4, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 1, 4, 2,
       2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 3, 1, 2, 2, 3,
       2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 1, 2, 2, 2,
       2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 4, 2, 2, 2, 2, 2,
       2, 1, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 3, 2, 2, 2, 4, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 4, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2,
       2, 2, 1, 2, 3, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 3,
       2, 2, 2, 3, 2, 2, 2, 2, 2, 1, 2, 2, 2, 4, 3, 1, 2, 2, 2, 2, 2, 2, 1,
       2, 2, 1, 3, 2, 1, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 3, 1, 3, 2, 2, 2, 2,
       2, 1, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 4, 2, 2, 1, 2,
       3, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 3, 2, 1, 2, 2, 2, 3, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 1, 3, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 4, 2, 2, 3, 1,
       1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 3, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 4, 2, 4, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 1, 3, 1, 1, 1, 4,
       4])
>>> Y = np.array([a], dtype = np.int)
>>> Y
array([[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2,
        4, 2, 0, 2, 2, 2, 2, 2, 3, 2, 2, 4, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2,
        3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2,
        3, 1, 2, 3, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2,
        1, 3, 4, 2, 2, 2, 2, 2, 1, 3, 3, 1, 1, 2, 2, 2, 2, 2, 2, 3, 2, 2,
        2, 2, 3, 2, 2, 1, 4, 2, 2, 0, 2, 2, 2, 2, 2, 3, 2, 3, 1, 1, 2, 2,
        1, 1, 2, 1, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2,
        2, 2, 2, 4, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 1, 2,
        2, 2, 2, 1, 4, 3, 2, 2, 2, 2, 2, 2, 0, 4, 2, 3, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2,
        2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 2,
        2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 1, 1, 2,
        2, 3, 2, 4, 2, 2, 2, 2, 2, 2, 2, 3, 4, 1, 0, 2, 2, 1, 2, 1, 2, 2,
        2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 1, 3, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2,
        2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2,
        4, 2, 2, 2, 2, 4, 3, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        1, 3, 2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 0, 2, 4, 2, 2, 3, 2, 4, 2, 3,
        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1,
        2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 0, 1, 2, 1, 2, 1, 4, 3, 2, 2, 2, 2,
        2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 4, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1,
        2, 1, 2, 3, 2, 2, 1, 2, 2, 2, 2, 2, 2, 4, 2, 1, 2, 1, 3, 3, 2, 2,
        2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 2, 3, 2, 2, 3, 2, 2, 2,
        4, 4, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 1, 4,
        2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 3, 1, 2,
        2, 3, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 1,
        2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 4, 2,
        2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 3, 2, 2, 2, 4,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1,
        2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 3, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,
        2, 2, 1, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 1, 2, 2, 2, 4, 3,
        1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 3, 2, 1, 2, 2, 2, 2, 3, 2, 2, 3,
        2, 2, 3, 1, 3, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2,
        1, 2, 1, 2, 2, 4, 2, 2, 1, 2, 3, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2,
        2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 1, 2, 2,
        2, 3, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 3, 2, 2,
        2, 2, 2, 2, 2, 1, 2, 2, 4, 2, 2, 3, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2,
        2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2,
        2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 1, 3, 1, 1, 1, 4, 4]])
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
>>> input_data
Traceback (most recent call last):
  File "<pyshell#171>", line 1, in <module>
    input_data
NameError: name 'input_data' is not defined
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
>>> input_data
Traceback (most recent call last):
  File "<pyshell#172>", line 1, in <module>
    input_data
NameError: name 'input_data' is not defined
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
>>> input_data
array([['1', '0', '0', ..., '610.0', '0.0', '2'],
       ['1', '0', '0', ..., '610.0', '0.0', '2'],
       ['1', '0', '0', ..., '1300.0', '762.0', '2'],
       ..., 
       ['1', '0', '0', ..., '150.0', '762.0', '2'],
       ['1', '0', '0', ..., '20.0', '0.0', '2'],
       ['1', '0', '0', ..., '610.0', '0.0', '2']], 
      dtype='<U21')
>>> input_data.shape
(898, 85)
>>> input_data.shape[0]
898
>>> input_data.shape[0] * 0.1
89.80000000000001
>>> input_data.shape[0] * 0.25
224.5
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
Traceback (most recent call last):
  File "/Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py", line 74, in <module>
    a = LabelEncoder().fit_transform(categorical[:, i])
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/label.py", line 112, in fit_transform
    self.classes_, y = np.unique(y, return_inverse=True)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/lib/arraysetops.py", line 211, in unique
    perm = ar.argsort(kind='mergesort' if return_index else 'quicksort')
TypeError: '>' not supported between instances of 'str' and 'int'
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
>>> input_data
array([['1', '0', '0', ..., '610.0', '0.0', '2'],
       ['1', '0', '0', ..., '610.0', '0.0', '2'],
       ['1', '0', '0', ..., '1300.0', '762.0', '2'],
       ..., 
       ['1', '0', '0', ..., '150.0', '762.0', '2'],
       ['1', '0', '0', ..., '20.0', '0.0', '2'],
       ['1', '0', '0', ..., '610.0', '0.0', '2']], 
      dtype='<U21')
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
Traceback (most recent call last):
  File "/Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py", line 74, in <module>
    a = LabelEncoder().fit_transform(categorical[:, i])
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/label.py", line 112, in fit_transform
    self.classes_, y = np.unique(y, return_inverse=True)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/lib/arraysetops.py", line 211, in unique
    perm = ar.argsort(kind='mergesort' if return_index else 'quicksort')
TypeError: '>' not supported between instances of 'str' and 'int'
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
anneal.arff
audiology.arff
Traceback (most recent call last):
  File "/Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py", line 76, in <module>
    a = LabelEncoder().fit_transform(categorical[:, i])
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/label.py", line 112, in fit_transform
    self.classes_, y = np.unique(y, return_inverse=True)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/lib/arraysetops.py", line 211, in unique
    perm = ar.argsort(kind='mergesort' if return_index else 'quicksort')
TypeError: '>' not supported between instances of 'str' and 'int'
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
anneal.arff
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
audiology.arff
0
1
2
3
Traceback (most recent call last):
  File "/Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py", line 77, in <module>
    a = LabelEncoder().fit_transform(categorical[:, i])
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/label.py", line 112, in fit_transform
    self.classes_, y = np.unique(y, return_inverse=True)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/lib/arraysetops.py", line 211, in unique
    perm = ar.argsort(kind='mergesort' if return_index else 'quicksort')
TypeError: '>' not supported between instances of 'str' and 'int'
>>> dataset['attributes']
[('age_gt_60', ['f', 't']), ('air', ['mild', 'moderate', 'normal', 'profound', 'severe']), ('airBoneGap', ['f', 't']), ('ar_c', ['absent', 'elevated', 'normal']), ('ar_u', ['absent', 'elevated', 'normal']), ('bone', ['mild', 'moderate', 'normal', 'unmeasured']), ('boneAbnormal', ['f', 't']), ('bser', ['degraded', 'normal']), ('history_buzzing', ['f', 't']), ('history_dizziness', ['f', 't']), ('history_fluctuating', ['f', 't']), ('history_fullness', ['f', 't']), ('history_heredity', ['f', 't']), ('history_nausea', ['f', 't']), ('history_noise', ['f', 't']), ('history_recruitment', ['f', 't']), ('history_ringing', ['f', 't']), ('history_roaring', ['f', 't']), ('history_vomiting', ['f', 't']), ('late_wave_poor', ['f', 't']), ('m_at_2k', ['f', 't']), ('m_cond_lt_1k', ['f', 't']), ('m_gt_1k', ['f', 't']), ('m_m_gt_2k', ['f', 't']), ('m_m_sn', ['f', 't']), ('m_m_sn_gt_1k', ['f', 't']), ('m_m_sn_gt_2k', ['f', 't']), ('m_m_sn_gt_500', ['f', 't']), ('m_p_sn_gt_2k', ['f', 't']), ('m_s_gt_500', ['f', 't']), ('m_s_sn', ['f', 't']), ('m_s_sn_gt_1k', ['f', 't']), ('m_s_sn_gt_2k', ['f', 't']), ('m_s_sn_gt_3k', ['f', 't']), ('m_s_sn_gt_4k', ['f', 't']), ('m_sn_2_3k', ['f', 't']), ('m_sn_gt_1k', ['f', 't']), ('m_sn_gt_2k', ['f', 't']), ('m_sn_gt_3k', ['f', 't']), ('m_sn_gt_4k', ['f', 't']), ('m_sn_gt_500', ['f', 't']), ('m_sn_gt_6k', ['f', 't']), ('m_sn_lt_1k', ['f', 't']), ('m_sn_lt_2k', ['f', 't']), ('m_sn_lt_3k', ['f', 't']), ('middle_wave_poor', ['f', 't']), ('mod_gt_4k', ['f', 't']), ('mod_mixed', ['f', 't']), ('mod_s_mixed', ['f', 't']), ('mod_s_sn_gt_500', ['f', 't']), ('mod_sn', ['f', 't']), ('mod_sn_gt_1k', ['f', 't']), ('mod_sn_gt_2k', ['f', 't']), ('mod_sn_gt_3k', ['f', 't']), ('mod_sn_gt_4k', ['f', 't']), ('mod_sn_gt_500', ['f', 't']), ('notch_4k', ['f', 't']), ('notch_at_4k', ['f', 't']), ('o_ar_c', ['absent', 'elevated', 'normal']), ('o_ar_u', ['absent', 'elevated', 'normal']), ('s_sn_gt_1k', ['f', 't']), ('s_sn_gt_2k', ['f', 't']), ('s_sn_gt_4k', ['f', 't']), ('speech', ['good', 'normal', 'poor', 'unmeasured', 'very_good', 'very_poor']), ('static_normal', ['f', 't']), ('tymp', ['a', 'ad', 'as', 'b', 'c']), ('viith_nerve_signs', ['f', 't']), ('wave_V_delayed', ['f', 't']), ('waveform_ItoV_prolonged', ['f', 't']), ('class', ['acoustic_neuroma', 'bells_palsy', 'cochlear_age', 'cochlear_age_and_noise', 'cochlear_age_plus_poss_menieres', 'cochlear_noise_and_heredity', 'cochlear_poss_noise', 'cochlear_unknown', 'conductive_discontinuity', 'conductive_fixation', 'mixed_cochlear_age_fixation', 'mixed_cochlear_age_otitis_media', 'mixed_cochlear_age_s_om', 'mixed_cochlear_unk_discontinuity', 'mixed_cochlear_unk_fixation', 'mixed_cochlear_unk_ser_om', 'mixed_poss_central_om', 'mixed_poss_noise_om', 'normal_ear', 'otitis_media', 'poss_central', 'possible_brainstem_disorder', 'possible_menieres', 'retrocochlear_unknown'])]
>>> data[0]
array(['t', 'mild', 'f', 'normal', 'normal', 'unmeasured', 'f', None, 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 't', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'normal',
       'normal', 'f', 'f', 'f', 'good', 't', 'a', 'f', 'f', 'f',
       'cochlear_age'], dtype=object)
>>> data
array([['t', 'mild', 'f', ..., 'f', 'f', 'cochlear_age'],
       ['t', 'mild', 'f', ..., 'f', 'f', 'cochlear_age'],
       ['t', 'normal', 'f', ..., 'f', 'f', 'cochlear_age_and_noise'],
       ..., 
       ['f', 'normal', 'f', ..., 'f', 'f', 'possible_brainstem_disorder'],
       ['t', 'mild', 'f', ..., 'f', 'f', 'cochlear_age'],
       ['t', 'normal', 'f', ..., 'f', 'f', 'cochlear_age']], dtype=object)
>>> for i in dataset['attributes']:
	print(i)

	
('age_gt_60', ['f', 't'])
('air', ['mild', 'moderate', 'normal', 'profound', 'severe'])
('airBoneGap', ['f', 't'])
('ar_c', ['absent', 'elevated', 'normal'])
('ar_u', ['absent', 'elevated', 'normal'])
('bone', ['mild', 'moderate', 'normal', 'unmeasured'])
('boneAbnormal', ['f', 't'])
('bser', ['degraded', 'normal'])
('history_buzzing', ['f', 't'])
('history_dizziness', ['f', 't'])
('history_fluctuating', ['f', 't'])
('history_fullness', ['f', 't'])
('history_heredity', ['f', 't'])
('history_nausea', ['f', 't'])
('history_noise', ['f', 't'])
('history_recruitment', ['f', 't'])
('history_ringing', ['f', 't'])
('history_roaring', ['f', 't'])
('history_vomiting', ['f', 't'])
('late_wave_poor', ['f', 't'])
('m_at_2k', ['f', 't'])
('m_cond_lt_1k', ['f', 't'])
('m_gt_1k', ['f', 't'])
('m_m_gt_2k', ['f', 't'])
('m_m_sn', ['f', 't'])
('m_m_sn_gt_1k', ['f', 't'])
('m_m_sn_gt_2k', ['f', 't'])
('m_m_sn_gt_500', ['f', 't'])
('m_p_sn_gt_2k', ['f', 't'])
('m_s_gt_500', ['f', 't'])
Traceback (most recent call last):
  File "<pyshell#184>", line 2, in <module>
    print(i)
KeyboardInterrupt
>>> categorial[:, 3]
Traceback (most recent call last):
  File "<pyshell#185>", line 1, in <module>
    categorial[:, 3]
NameError: name 'categorial' is not defined
>>> categorical[:, 3]
array(['normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'absent', 'absent',
       'elevated', 'elevated', 'normal', 'normal', 'absent', 'absent',
       'normal', 'normal', 'absent', 'elevated', 'absent', 'absent',
       'elevated', 'elevated', 'normal', 'normal', 3, 3, 'normal',
       'normal', 'normal', 'normal', 3, 'elevated', 'normal', 'normal',
       'normal', 'elevated', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'elevated', 'normal', 'normal', 'normal', 'absent', 'elevated',
       'normal', 'elevated', 'normal', 'elevated', 'absent', 'absent',
       'absent', 'absent', 'absent', 'normal', 'elevated', 'normal',
       'normal', 'elevated', 'elevated', 'absent', 'absent', 'absent',
       'absent', 'normal', 'normal', 'elevated', 'absent', 'absent',
       'elevated', 'elevated', 'normal', 'normal', 'normal', 'normal',
       'elevated', 'normal', 'normal', 'elevated', 'normal', 'absent',
       'elevated', 'absent', 'absent', 'elevated', 'elevated', 'absent',
       'normal', 'elevated', 'absent', 'absent', 'absent', 'normal',
       'normal', 'absent', 'absent', 'absent', 'absent', 'normal',
       'elevated', 'elevated', 'absent', 'absent', 'elevated', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'elevated', 'normal', 'normal', 'absent', 'absent',
       'absent', 'normal', 'absent', 'normal', 'normal', 'normal',
       'elevated', 'absent', 'normal', 'absent', 'absent', 'absent',
       'absent', 'absent', 'absent', 'absent', 'elevated', 'normal', 3,
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'absent', 'normal', 'absent', 'elevated', 'normal',
       'absent', 'absent', 'normal', 'normal', 'normal', 'normal',
       'elevated', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'absent', 'normal',
       'normal', 'normal', 'absent', 'absent', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'absent', 'normal', 'normal', 'normal', 'normal',
       'elevated', 'elevated', 'normal', 'normal', 'absent', 'elevated',
       'normal', 'absent', 'absent', 'absent', 'normal', 'normal',
       'normal', 'normal', 'absent', 'normal', 'normal', 'normal', 'normal'], dtype=object)
>>> a = LabelEncoder().fit_transform(categorical[:, 3])
Traceback (most recent call last):
  File "<pyshell#187>", line 1, in <module>
    a = LabelEncoder().fit_transform(categorical[:, 3])
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/label.py", line 112, in fit_transform
    self.classes_, y = np.unique(y, return_inverse=True)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/lib/arraysetops.py", line 211, in unique
    perm = ar.argsort(kind='mergesort' if return_index else 'quicksort')
TypeError: '>' not supported between instances of 'str' and 'int'
>>> data[28]
array(['t', 'mild', 't', None, 'absent', 'mild', 't', None, 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', None, 'absent', 'f', 'f',
       'f', 'normal', 't', 'as', 'f', 'f', 'f',
       'mixed_cochlear_age_fixation'], dtype=object)
>>> data[29]
array(['t', 'mild', 't', None, 'absent', 'mild', 'f', None, 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', None, 'absent', 'f', 'f',
       'f', 'normal', 't', 'b', 'f', 'f', 'f',
       'mixed_cochlear_age_otitis_media'], dtype=object)
>>> categorical[:, 3]
array(['normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'absent', 'absent',
       'elevated', 'elevated', 'normal', 'normal', 'absent', 'absent',
       'normal', 'normal', 'absent', 'elevated', 'absent', 'absent',
       'elevated', 'elevated', 'normal', 'normal', 3, 3, 'normal',
       'normal', 'normal', 'normal', 3, 'elevated', 'normal', 'normal',
       'normal', 'elevated', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'elevated', 'normal', 'normal', 'normal', 'absent', 'elevated',
       'normal', 'elevated', 'normal', 'elevated', 'absent', 'absent',
       'absent', 'absent', 'absent', 'normal', 'elevated', 'normal',
       'normal', 'elevated', 'elevated', 'absent', 'absent', 'absent',
       'absent', 'normal', 'normal', 'elevated', 'absent', 'absent',
       'elevated', 'elevated', 'normal', 'normal', 'normal', 'normal',
       'elevated', 'normal', 'normal', 'elevated', 'normal', 'absent',
       'elevated', 'absent', 'absent', 'elevated', 'elevated', 'absent',
       'normal', 'elevated', 'absent', 'absent', 'absent', 'normal',
       'normal', 'absent', 'absent', 'absent', 'absent', 'normal',
       'elevated', 'elevated', 'absent', 'absent', 'elevated', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'elevated', 'normal', 'normal', 'absent', 'absent',
       'absent', 'normal', 'absent', 'normal', 'normal', 'normal',
       'elevated', 'absent', 'normal', 'absent', 'absent', 'absent',
       'absent', 'absent', 'absent', 'absent', 'elevated', 'normal', 3,
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'absent', 'normal', 'absent', 'elevated', 'normal',
       'absent', 'absent', 'normal', 'normal', 'normal', 'normal',
       'elevated', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'absent', 'normal',
       'normal', 'normal', 'absent', 'absent', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'absent', 'normal', 'normal', 'normal', 'normal',
       'elevated', 'elevated', 'normal', 'normal', 'absent', 'elevated',
       'normal', 'absent', 'absent', 'absent', 'normal', 'normal',
       'normal', 'normal', 'absent', 'normal', 'normal', 'normal', 'normal'], dtype=object)
>>> categorical[0]
array(['t', 'mild', 'f', 'normal', 'normal', 'unmeasured', 'f', 2, 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 't', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'normal',
       'normal', 'f', 'f', 'f', 'good', 't', 'a', 'f', 'f', 'f'], dtype=object)
>>> categorical[1]
array(['t', 'mild', 'f', 'normal', 'normal', 'unmeasured', 'f', 2, 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 't', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'normal',
       'normal', 'f', 'f', 'f', 'good', 't', 'a', 'f', 'f', 'f'], dtype=object)
>>> categorical[28]
array(['t', 'mild', 't', 3, 'absent', 'mild', 't', 2, 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 3, 'absent', 'f', 'f', 'f',
       'normal', 't', 'as', 'f', 'f', 'f'], dtype=object)
>>> len(categorical[28])
69
>>> len(categorical[1])
69
>>> dataset['attributes'][3]
('ar_c', ['absent', 'elevated', 'normal'])
>>> dataset['attributes'][2]
('airBoneGap', ['f', 't'])
>>> dataset['attributes'][4]
('ar_u', ['absent', 'elevated', 'normal'])
>>> dataset['attributes'][5]
('bone', ['mild', 'moderate', 'normal', 'unmeasured'])
>>> categorical[29]
array(['t', 'mild', 't', 3, 'absent', 'mild', 'f', 2, 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 3, 'absent', 'f', 'f', 'f',
       'normal', 't', 'b', 'f', 'f', 'f'], dtype=object)
>>> categorical[30]
array(['t', 'mild', 'f', 'normal', 'normal', 'mild', 't', 2, 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'normal', 'normal', 'f',
       'f', 'f', 'good', 't', 'a', 'f', 'f', 'f'], dtype=object)
>>> data[28]
array(['t', 'mild', 't', None, 'absent', 'mild', 't', None, 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', None, 'absent', 'f', 'f',
       'f', 'normal', 't', 'as', 'f', 'f', 'f',
       'mixed_cochlear_age_fixation'], dtype=object)
>>> dataset['attributes']
[('age_gt_60', ['f', 't']), ('air', ['mild', 'moderate', 'normal', 'profound', 'severe']), ('airBoneGap', ['f', 't']), ('ar_c', ['absent', 'elevated', 'normal']), ('ar_u', ['absent', 'elevated', 'normal']), ('bone', ['mild', 'moderate', 'normal', 'unmeasured']), ('boneAbnormal', ['f', 't']), ('bser', ['degraded', 'normal']), ('history_buzzing', ['f', 't']), ('history_dizziness', ['f', 't']), ('history_fluctuating', ['f', 't']), ('history_fullness', ['f', 't']), ('history_heredity', ['f', 't']), ('history_nausea', ['f', 't']), ('history_noise', ['f', 't']), ('history_recruitment', ['f', 't']), ('history_ringing', ['f', 't']), ('history_roaring', ['f', 't']), ('history_vomiting', ['f', 't']), ('late_wave_poor', ['f', 't']), ('m_at_2k', ['f', 't']), ('m_cond_lt_1k', ['f', 't']), ('m_gt_1k', ['f', 't']), ('m_m_gt_2k', ['f', 't']), ('m_m_sn', ['f', 't']), ('m_m_sn_gt_1k', ['f', 't']), ('m_m_sn_gt_2k', ['f', 't']), ('m_m_sn_gt_500', ['f', 't']), ('m_p_sn_gt_2k', ['f', 't']), ('m_s_gt_500', ['f', 't']), ('m_s_sn', ['f', 't']), ('m_s_sn_gt_1k', ['f', 't']), ('m_s_sn_gt_2k', ['f', 't']), ('m_s_sn_gt_3k', ['f', 't']), ('m_s_sn_gt_4k', ['f', 't']), ('m_sn_2_3k', ['f', 't']), ('m_sn_gt_1k', ['f', 't']), ('m_sn_gt_2k', ['f', 't']), ('m_sn_gt_3k', ['f', 't']), ('m_sn_gt_4k', ['f', 't']), ('m_sn_gt_500', ['f', 't']), ('m_sn_gt_6k', ['f', 't']), ('m_sn_lt_1k', ['f', 't']), ('m_sn_lt_2k', ['f', 't']), ('m_sn_lt_3k', ['f', 't']), ('middle_wave_poor', ['f', 't']), ('mod_gt_4k', ['f', 't']), ('mod_mixed', ['f', 't']), ('mod_s_mixed', ['f', 't']), ('mod_s_sn_gt_500', ['f', 't']), ('mod_sn', ['f', 't']), ('mod_sn_gt_1k', ['f', 't']), ('mod_sn_gt_2k', ['f', 't']), ('mod_sn_gt_3k', ['f', 't']), ('mod_sn_gt_4k', ['f', 't']), ('mod_sn_gt_500', ['f', 't']), ('notch_4k', ['f', 't']), ('notch_at_4k', ['f', 't']), ('o_ar_c', ['absent', 'elevated', 'normal']), ('o_ar_u', ['absent', 'elevated', 'normal']), ('s_sn_gt_1k', ['f', 't']), ('s_sn_gt_2k', ['f', 't']), ('s_sn_gt_4k', ['f', 't']), ('speech', ['good', 'normal', 'poor', 'unmeasured', 'very_good', 'very_poor']), ('static_normal', ['f', 't']), ('tymp', ['a', 'ad', 'as', 'b', 'c']), ('viith_nerve_signs', ['f', 't']), ('wave_V_delayed', ['f', 't']), ('waveform_ItoV_prolonged', ['f', 't']), ('class', ['acoustic_neuroma', 'bells_palsy', 'cochlear_age', 'cochlear_age_and_noise', 'cochlear_age_plus_poss_menieres', 'cochlear_noise_and_heredity', 'cochlear_poss_noise', 'cochlear_unknown', 'conductive_discontinuity', 'conductive_fixation', 'mixed_cochlear_age_fixation', 'mixed_cochlear_age_otitis_media', 'mixed_cochlear_age_s_om', 'mixed_cochlear_unk_discontinuity', 'mixed_cochlear_unk_fixation', 'mixed_cochlear_unk_ser_om', 'mixed_poss_central_om', 'mixed_poss_noise_om', 'normal_ear', 'otitis_media', 'poss_central', 'possible_brainstem_disorder', 'possible_menieres', 'retrocochlear_unknown'])]
>>> dataset['attributes'][3]
('ar_c', ['absent', 'elevated', 'normal'])
>>> 
>>> dataset['attributes'][3][]
SyntaxError: invalid syntax
>>> dataset['attributes'][3][1]
['absent', 'elevated', 'normal']
>>> len(data[0])
70
>>> len(X[0])
69
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
anneal.arff
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
audiology.arff
0
1
2
3
Traceback (most recent call last):
  File "/Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py", line 77, in <module>
    a = LabelEncoder().fit_transform(categorical[:, i])
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/label.py", line 112, in fit_transform
    self.classes_, y = np.unique(y, return_inverse=True)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/lib/arraysetops.py", line 211, in unique
    perm = ar.argsort(kind='mergesort' if return_index else 'quicksort')
TypeError: '>' not supported between instances of 'str' and 'list'
>>> X[28]
array(['t', 'mild', 't', ['absent', 'elevated', 'normal'], 'absent',
       'mild', 't', ['degraded', 'normal'], 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', ['absent', 'elevated', 'normal'], 'absent',
       'f', 'f', 'f', 'normal', 't', 'as', 'f', 'f', 'f'], dtype=object)
>>> 'asdf' < '0'
False
>>> ord('0')
48
>>> ord('a')
97
>>> chr(47)
'/'
>>> chr(47)
'/'
>>> for i in range(0, 48):
	print(chr(i))

	
 








	









Traceback (most recent call last):
  File "<pyshell#218>", line 2, in <module>
    print(chr(i))
KeyboardInterrupt
>>> chr(6)
'\x06'
>>> print(chr(6))

>>> for i in range(0, 48):
	print(chr(i))

	
 








	























 
!
"
#
$
%
&
'
(
)
*
+
,
-
.
/
>>> '-3' < '0'
True
>>> chr(ord('-3') + 7)
Traceback (most recent call last):
  File "<pyshell#224>", line 1, in <module>
    chr(ord('-3') + 7)
TypeError: ord() expected a character, but string of length 2 found
>>> ord('')
Traceback (most recent call last):
  File "<pyshell#225>", line 1, in <module>
    ord('')
TypeError: ord() expected a character, but string of length 0 found

>>> LabelEncoder().fit_transform([1,2,3])
array([0, 1, 2])
>>> LabelEncoder().fit_transform([1,2,3, 'a'])
array([0, 1, 2, 3])
>>> LabelEncoder().fit_transform([1,2,3, 'a'])
array([0, 1, 2, 3])
>>> LabelEncoder().fit_transform([1,2,3, 'a'])
array([0, 1, 2, 3])
>>> LabelEncoder().fit_transform([1,2,3, 'a'])
array([0, 1, 2, 3])
>>> LabelEncoder().fit_transform([1,2,3, 'a'])
array([0, 1, 2, 3])
>>> LabelEncoder().fit_transform([1,2,3, 'a'])
array([0, 1, 2, 3])
>>> LabelEncoder().fit_transform([1,2,3, 'a'])
array([0, 1, 2, 3])
>>> LabelEncoder().fit_transform([1,2,3, 'a', '1'])
array([0, 1, 2, 3, 0])
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
anneal.arff
Traceback (most recent call last):
  File "/Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py", line 39, in <module>
    if Y[i] < 0:
TypeError: '<' not supported between instances of 'numpy.str_' and 'int'
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
anneal.arff
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
audiology.arff
0
1
2
3
Traceback (most recent call last):
  File "/Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py", line 77, in <module>
    a = LabelEncoder().fit_transform(categorical[:, i])
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/label.py", line 112, in fit_transform
    self.classes_, y = np.unique(y, return_inverse=True)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/lib/arraysetops.py", line 211, in unique
    perm = ar.argsort(kind='mergesort' if return_index else 'quicksort')
TypeError: '>' not supported between instances of 'str' and 'int'
>>> data[28]
array(['t', 'mild', 't', None, 'absent', 'mild', 't', None, 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', None, 'absent', 'f', 'f',
       'f', 'normal', 't', 'as', 'f', 'f', 'f',
       'mixed_cochlear_age_fixation'], dtype=object)
>>> categorical[:,3]
array(['normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'absent', 'absent',
       'elevated', 'elevated', 'normal', 'normal', 'absent', 'absent',
       'normal', 'normal', 'absent', 'elevated', 'absent', 'absent',
       'elevated', 'elevated', 'normal', 'normal', 3, 3, 'normal',
       'normal', 'normal', 'normal', 3, 'elevated', 'normal', 'normal',
       'normal', 'elevated', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'elevated', 'normal', 'normal', 'normal', 'absent', 'elevated',
       'normal', 'elevated', 'normal', 'elevated', 'absent', 'absent',
       'absent', 'absent', 'absent', 'normal', 'elevated', 'normal',
       'normal', 'elevated', 'elevated', 'absent', 'absent', 'absent',
       'absent', 'normal', 'normal', 'elevated', 'absent', 'absent',
       'elevated', 'elevated', 'normal', 'normal', 'normal', 'normal',
       'elevated', 'normal', 'normal', 'elevated', 'normal', 'absent',
       'elevated', 'absent', 'absent', 'elevated', 'elevated', 'absent',
       'normal', 'elevated', 'absent', 'absent', 'absent', 'normal',
       'normal', 'absent', 'absent', 'absent', 'absent', 'normal',
       'elevated', 'elevated', 'absent', 'absent', 'elevated', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'elevated', 'normal', 'normal', 'absent', 'absent',
       'absent', 'normal', 'absent', 'normal', 'normal', 'normal',
       'elevated', 'absent', 'normal', 'absent', 'absent', 'absent',
       'absent', 'absent', 'absent', 'absent', 'elevated', 'normal', 3,
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'absent', 'normal', 'absent', 'elevated', 'normal',
       'absent', 'absent', 'normal', 'normal', 'normal', 'normal',
       'elevated', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'absent', 'normal',
       'normal', 'normal', 'absent', 'absent', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'absent', 'normal', 'normal', 'normal', 'normal',
       'elevated', 'elevated', 'normal', 'normal', 'absent', 'elevated',
       'normal', 'absent', 'absent', 'absent', 'normal', 'normal',
       'normal', 'normal', 'absent', 'normal', 'normal', 'normal', 'normal'], dtype=object)
>>> L = ['normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'absent', 'absent',
       'elevated', 'elevated', 'normal', 'normal', 'absent', 'absent',
       'normal', 'normal', 'absent', 'elevated', 'absent', 'absent',
       'elevated', 'elevated', 'normal', 'normal', 3, 3, 'normal',
       'normal', 'normal', 'normal', 3, 'elevated', 'normal', 'normal',
       'normal', 'elevated', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'elevated', 'normal', 'normal', 'normal', 'absent', 'elevated',
       'normal', 'elevated', 'normal', 'elevated', 'absent', 'absent',
       'absent', 'absent', 'absent', 'normal', 'elevated', 'normal',
       'normal', 'elevated', 'elevated', 'absent', 'absent', 'absent',
       'absent', 'normal', 'normal', 'elevated', 'absent', 'absent',
       'elevated', 'elevated', 'normal', 'normal', 'normal', 'normal',
       'elevated', 'normal', 'normal', 'elevated', 'normal', 'absent',
       'elevated', 'absent', 'absent', 'elevated', 'elevated', 'absent',
       'normal', 'elevated', 'absent', 'absent', 'absent', 'normal',
       'normal', 'absent', 'absent', 'absent', 'absent', 'normal',
       'elevated', 'elevated', 'absent', 'absent', 'elevated', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'elevated', 'normal', 'normal', 'absent', 'absent',
       'absent', 'normal', 'absent', 'normal', 'normal', 'normal',
       'elevated', 'absent', 'normal', 'absent', 'absent', 'absent',
       'absent', 'absent', 'absent', 'absent', 'elevated', 'normal', 3,
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'absent', 'normal', 'absent', 'elevated', 'normal',
       'absent', 'absent', 'normal', 'normal', 'normal', 'normal',
       'elevated', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'absent', 'normal',
       'normal', 'normal', 'absent', 'absent', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'absent', 'normal', 'normal', 'normal', 'normal',
       'elevated', 'elevated', 'normal', 'normal', 'absent', 'elevated',
       'normal', 'absent', 'absent', 'absent', 'normal', 'normal',
       'normal', 'normal', 'absent', 'normal', 'normal', 'normal', 'normal']
>>> len(L)
226
>>> L[0]
'normal'
>>> L[1]
'normal'
>>> L
['normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'absent', 'absent', 'elevated', 'elevated', 'normal', 'normal', 'absent', 'absent', 'normal', 'normal', 'absent', 'elevated', 'absent', 'absent', 'elevated', 'elevated', 'normal', 'normal', 3, 3, 'normal', 'normal', 'normal', 'normal', 3, 'elevated', 'normal', 'normal', 'normal', 'elevated', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'elevated', 'normal', 'normal', 'normal', 'absent', 'elevated', 'normal', 'elevated', 'normal', 'elevated', 'absent', 'absent', 'absent', 'absent', 'absent', 'normal', 'elevated', 'normal', 'normal', 'elevated', 'elevated', 'absent', 'absent', 'absent', 'absent', 'normal', 'normal', 'elevated', 'absent', 'absent', 'elevated', 'elevated', 'normal', 'normal', 'normal', 'normal', 'elevated', 'normal', 'normal', 'elevated', 'normal', 'absent', 'elevated', 'absent', 'absent', 'elevated', 'elevated', 'absent', 'normal', 'elevated', 'absent', 'absent', 'absent', 'normal', 'normal', 'absent', 'absent', 'absent', 'absent', 'normal', 'elevated', 'elevated', 'absent', 'absent', 'elevated', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'elevated', 'normal', 'normal', 'absent', 'absent', 'absent', 'normal', 'absent', 'normal', 'normal', 'normal', 'elevated', 'absent', 'normal', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'elevated', 'normal', 3, 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'absent', 'normal', 'absent', 'elevated', 'normal', 'absent', 'absent', 'normal', 'normal', 'normal', 'normal', 'elevated', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'absent', 'normal', 'normal', 'normal', 'absent', 'absent', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'absent', 'normal', 'normal', 'normal', 'normal', 'elevated', 'elevated', 'normal', 'normal', 'absent', 'elevated', 'normal', 'absent', 'absent', 'absent', 'normal', 'normal', 'normal', 'normal', 'absent', 'normal', 'normal', 'normal', 'normal']
>>> a = LabelEncoder().fit_transform(L)
>>> A
Traceback (most recent call last):
  File "<pyshell#243>", line 1, in <module>
    A
NameError: name 'A' is not defined
>>> a
array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 2, 2, 3, 3, 1, 1, 3, 3, 1, 2, 1,
       1, 2, 2, 3, 3, 0, 0, 3, 3, 3, 3, 0, 2, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3,
       3, 3, 3, 3, 2, 3, 3, 3, 1, 2, 3, 2, 3, 2, 1, 1, 1, 1, 1, 3, 2, 3, 3,
       2, 2, 1, 1, 1, 1, 3, 3, 2, 1, 1, 2, 2, 3, 3, 3, 3, 2, 3, 3, 2, 3, 1,
       2, 1, 1, 2, 2, 1, 3, 2, 1, 1, 1, 3, 3, 1, 1, 1, 1, 3, 2, 2, 1, 1, 2,
       3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 1, 1, 1, 3, 1, 3, 3, 3, 2, 1, 3, 1,
       1, 1, 1, 1, 1, 1, 2, 3, 0, 3, 3, 3, 3, 3, 3, 3, 1, 3, 1, 2, 3, 1, 1,
       3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
       3, 3, 3, 1, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3,
       2, 2, 3, 3, 1, 2, 3, 1, 1, 1, 3, 3, 3, 3, 1, 3, 3, 3, 3])
>>> a = LabelEncoder().fit_transform(categorical[:, 3])
Traceback (most recent call last):
  File "<pyshell#245>", line 1, in <module>
    a = LabelEncoder().fit_transform(categorical[:, 3])
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/label.py", line 112, in fit_transform
    self.classes_, y = np.unique(y, return_inverse=True)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/lib/arraysetops.py", line 211, in unique
    perm = ar.argsort(kind='mergesort' if return_index else 'quicksort')
TypeError: '>' not supported between instances of 'str' and 'int'
>>> L = categorical[:, 3]
>>> a = LabelEncoder().fit_transform(L)
Traceback (most recent call last):
  File "<pyshell#247>", line 1, in <module>
    a = LabelEncoder().fit_transform(L)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/label.py", line 112, in fit_transform
    self.classes_, y = np.unique(y, return_inverse=True)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/lib/arraysetops.py", line 211, in unique
    perm = ar.argsort(kind='mergesort' if return_index else 'quicksort')
TypeError: '>' not supported between instances of 'str' and 'int'
>>> L
array(['normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'absent', 'absent',
       'elevated', 'elevated', 'normal', 'normal', 'absent', 'absent',
       'normal', 'normal', 'absent', 'elevated', 'absent', 'absent',
       'elevated', 'elevated', 'normal', 'normal', 3, 3, 'normal',
       'normal', 'normal', 'normal', 3, 'elevated', 'normal', 'normal',
       'normal', 'elevated', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'elevated', 'normal', 'normal', 'normal', 'absent', 'elevated',
       'normal', 'elevated', 'normal', 'elevated', 'absent', 'absent',
       'absent', 'absent', 'absent', 'normal', 'elevated', 'normal',
       'normal', 'elevated', 'elevated', 'absent', 'absent', 'absent',
       'absent', 'normal', 'normal', 'elevated', 'absent', 'absent',
       'elevated', 'elevated', 'normal', 'normal', 'normal', 'normal',
       'elevated', 'normal', 'normal', 'elevated', 'normal', 'absent',
       'elevated', 'absent', 'absent', 'elevated', 'elevated', 'absent',
       'normal', 'elevated', 'absent', 'absent', 'absent', 'normal',
       'normal', 'absent', 'absent', 'absent', 'absent', 'normal',
       'elevated', 'elevated', 'absent', 'absent', 'elevated', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'elevated', 'normal', 'normal', 'absent', 'absent',
       'absent', 'normal', 'absent', 'normal', 'normal', 'normal',
       'elevated', 'absent', 'normal', 'absent', 'absent', 'absent',
       'absent', 'absent', 'absent', 'absent', 'elevated', 'normal', 3,
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'absent', 'normal', 'absent', 'elevated', 'normal',
       'absent', 'absent', 'normal', 'normal', 'normal', 'normal',
       'elevated', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'absent', 'normal',
       'normal', 'normal', 'absent', 'absent', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'absent', 'normal', 'normal', 'normal', 'normal',
       'elevated', 'elevated', 'normal', 'normal', 'absent', 'elevated',
       'normal', 'absent', 'absent', 'absent', 'normal', 'normal',
       'normal', 'normal', 'absent', 'normal', 'normal', 'normal', 'normal'], dtype=object)
>>> categorical[:, 3]
array(['normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'absent', 'absent',
       'elevated', 'elevated', 'normal', 'normal', 'absent', 'absent',
       'normal', 'normal', 'absent', 'elevated', 'absent', 'absent',
       'elevated', 'elevated', 'normal', 'normal', 3, 3, 'normal',
       'normal', 'normal', 'normal', 3, 'elevated', 'normal', 'normal',
       'normal', 'elevated', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'elevated', 'normal', 'normal', 'normal', 'absent', 'elevated',
       'normal', 'elevated', 'normal', 'elevated', 'absent', 'absent',
       'absent', 'absent', 'absent', 'normal', 'elevated', 'normal',
       'normal', 'elevated', 'elevated', 'absent', 'absent', 'absent',
       'absent', 'normal', 'normal', 'elevated', 'absent', 'absent',
       'elevated', 'elevated', 'normal', 'normal', 'normal', 'normal',
       'elevated', 'normal', 'normal', 'elevated', 'normal', 'absent',
       'elevated', 'absent', 'absent', 'elevated', 'elevated', 'absent',
       'normal', 'elevated', 'absent', 'absent', 'absent', 'normal',
       'normal', 'absent', 'absent', 'absent', 'absent', 'normal',
       'elevated', 'elevated', 'absent', 'absent', 'elevated', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'elevated', 'normal', 'normal', 'absent', 'absent',
       'absent', 'normal', 'absent', 'normal', 'normal', 'normal',
       'elevated', 'absent', 'normal', 'absent', 'absent', 'absent',
       'absent', 'absent', 'absent', 'absent', 'elevated', 'normal', 3,
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'absent', 'normal', 'absent', 'elevated', 'normal',
       'absent', 'absent', 'normal', 'normal', 'normal', 'normal',
       'elevated', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'absent', 'normal',
       'normal', 'normal', 'absent', 'absent', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'absent', 'normal', 'normal', 'normal', 'normal',
       'elevated', 'elevated', 'normal', 'normal', 'absent', 'elevated',
       'normal', 'absent', 'absent', 'absent', 'normal', 'normal',
       'normal', 'normal', 'absent', 'normal', 'normal', 'normal', 'normal'], dtype=object)
>>> categorical[:, 3][0]
'normal'
>>> categorical[:, 2]
array(['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 't', 'f', 'f', 'f', 't', 'f', 't', 'f', 'f',
       'f', 'f', 't', 't', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 't', 'f', 'f', 'f', 't',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 't', 'f', 'f', 'f', 'f', 'f',
       'f', 't', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 't', 't', 't', 'f', 'f', 'f', 't', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 't', 't', 't', 't',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 't', 'f', 'f', 'f', 'f', 'f',
       'f', 't', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       't', 'f', 'f', 't', 't', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 't', 't', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 't', 't', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f'], dtype=object)
>>> categorical[:, 2]
array(['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 't', 'f', 'f', 'f', 't', 'f', 't', 'f', 'f',
       'f', 'f', 't', 't', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 't', 'f', 'f', 'f', 't',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 't', 'f', 'f', 'f', 'f', 'f',
       'f', 't', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 't', 't', 't', 'f', 'f', 'f', 't', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 't', 't', 't', 't',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 't', 'f', 'f', 'f', 'f', 'f',
       'f', 't', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       't', 'f', 'f', 't', 't', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 't', 't', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f', 'f', 't', 't', 'f', 'f', 'f', 'f', 'f',
       'f', 'f', 'f', 'f', 'f'], dtype=object)
>>> 
>>> categorical[:, 3]
array(['normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'absent', 'absent',
       'elevated', 'elevated', 'normal', 'normal', 'absent', 'absent',
       'normal', 'normal', 'absent', 'elevated', 'absent', 'absent',
       'elevated', 'elevated', 'normal', 'normal', 3, 3, 'normal',
       'normal', 'normal', 'normal', 3, 'elevated', 'normal', 'normal',
       'normal', 'elevated', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'elevated', 'normal', 'normal', 'normal', 'absent', 'elevated',
       'normal', 'elevated', 'normal', 'elevated', 'absent', 'absent',
       'absent', 'absent', 'absent', 'normal', 'elevated', 'normal',
       'normal', 'elevated', 'elevated', 'absent', 'absent', 'absent',
       'absent', 'normal', 'normal', 'elevated', 'absent', 'absent',
       'elevated', 'elevated', 'normal', 'normal', 'normal', 'normal',
       'elevated', 'normal', 'normal', 'elevated', 'normal', 'absent',
       'elevated', 'absent', 'absent', 'elevated', 'elevated', 'absent',
       'normal', 'elevated', 'absent', 'absent', 'absent', 'normal',
       'normal', 'absent', 'absent', 'absent', 'absent', 'normal',
       'elevated', 'elevated', 'absent', 'absent', 'elevated', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'elevated', 'normal', 'normal', 'absent', 'absent',
       'absent', 'normal', 'absent', 'normal', 'normal', 'normal',
       'elevated', 'absent', 'normal', 'absent', 'absent', 'absent',
       'absent', 'absent', 'absent', 'absent', 'elevated', 'normal', 3,
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'absent', 'normal', 'absent', 'elevated', 'normal',
       'absent', 'absent', 'normal', 'normal', 'normal', 'normal',
       'elevated', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'absent', 'normal',
       'normal', 'normal', 'absent', 'absent', 'normal', 'normal',
       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',
       'normal', 'absent', 'normal', 'normal', 'normal', 'normal',
       'elevated', 'elevated', 'normal', 'normal', 'absent', 'elevated',
       'normal', 'absent', 'absent', 'absent', 'normal', 'normal',
       'normal', 'normal', 'absent', 'normal', 'normal', 'normal', 'normal'], dtype=object)
>>> a = LabelEncoder().fit_transform(categorical[:, i])
Traceback (most recent call last):
  File "<pyshell#255>", line 1, in <module>
    a = LabelEncoder().fit_transform(categorical[:, i])
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/label.py", line 112, in fit_transform
    self.classes_, y = np.unique(y, return_inverse=True)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/lib/arraysetops.py", line 211, in unique
    perm = ar.argsort(kind='mergesort' if return_index else 'quicksort')
TypeError: '>' not supported between instances of 'str' and 'int'
>>> L = categorical[:, 3]
>>> L.shape
(226,)
>>> list(L)
['normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'absent', 'absent', 'elevated', 'elevated', 'normal', 'normal', 'absent', 'absent', 'normal', 'normal', 'absent', 'elevated', 'absent', 'absent', 'elevated', 'elevated', 'normal', 'normal', 3, 3, 'normal', 'normal', 'normal', 'normal', 3, 'elevated', 'normal', 'normal', 'normal', 'elevated', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'elevated', 'normal', 'normal', 'normal', 'absent', 'elevated', 'normal', 'elevated', 'normal', 'elevated', 'absent', 'absent', 'absent', 'absent', 'absent', 'normal', 'elevated', 'normal', 'normal', 'elevated', 'elevated', 'absent', 'absent', 'absent', 'absent', 'normal', 'normal', 'elevated', 'absent', 'absent', 'elevated', 'elevated', 'normal', 'normal', 'normal', 'normal', 'elevated', 'normal', 'normal', 'elevated', 'normal', 'absent', 'elevated', 'absent', 'absent', 'elevated', 'elevated', 'absent', 'normal', 'elevated', 'absent', 'absent', 'absent', 'normal', 'normal', 'absent', 'absent', 'absent', 'absent', 'normal', 'elevated', 'elevated', 'absent', 'absent', 'elevated', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'elevated', 'normal', 'normal', 'absent', 'absent', 'absent', 'normal', 'absent', 'normal', 'normal', 'normal', 'elevated', 'absent', 'normal', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'elevated', 'normal', 3, 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'absent', 'normal', 'absent', 'elevated', 'normal', 'absent', 'absent', 'normal', 'normal', 'normal', 'normal', 'elevated', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'absent', 'normal', 'normal', 'normal', 'absent', 'absent', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'absent', 'normal', 'normal', 'normal', 'normal', 'elevated', 'elevated', 'normal', 'normal', 'absent', 'elevated', 'normal', 'absent', 'absent', 'absent', 'normal', 'normal', 'normal', 'normal', 'absent', 'normal', 'normal', 'normal', 'normal']
>>> a = LabelEncoder().fit_transform(list(L))
>>> 
>>> a
array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 2, 2, 3, 3, 1, 1, 3, 3, 1, 2, 1,
       1, 2, 2, 3, 3, 0, 0, 3, 3, 3, 3, 0, 2, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3,
       3, 3, 3, 3, 2, 3, 3, 3, 1, 2, 3, 2, 3, 2, 1, 1, 1, 1, 1, 3, 2, 3, 3,
       2, 2, 1, 1, 1, 1, 3, 3, 2, 1, 1, 2, 2, 3, 3, 3, 3, 2, 3, 3, 2, 3, 1,
       2, 1, 1, 2, 2, 1, 3, 2, 1, 1, 1, 3, 3, 1, 1, 1, 1, 3, 2, 2, 1, 1, 2,
       3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 1, 1, 1, 3, 1, 3, 3, 3, 2, 1, 3, 1,
       1, 1, 1, 1, 1, 1, 2, 3, 0, 3, 3, 3, 3, 3, 3, 3, 1, 3, 1, 2, 3, 1, 1,
       3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
       3, 3, 3, 1, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3,
       2, 2, 3, 3, 1, 2, 3, 1, 1, 1, 3, 3, 3, 3, 1, 3, 3, 3, 3])
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
anneal.arff
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
audiology.arff
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
autos.arff
0
1
2
3
4
5
6
7
8
9
credit-a.arff
0
1
2
3
4
5
6
7
8
hypothyroid.arff
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
letter.arff
Traceback (most recent call last):
  File "/Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py", line 114, in <module>
    input_data = np.concatenate((transformed_X, Y.T), axis = 1)
ValueError: all the input array dimensions except for the concatenation axis must match exactly
>>> X
array([['2', '4', '4', ..., '8', '5', '6'],
       ['4', '7', '5', ..., '9', '7', '10'],
       ['7', '10', '8', ..., '5', '5', '10'],
       ..., 
       ['4', '8', '4', ..., '9', '3', '7'],
       ['4', '11', '4', ..., '8', '0', '8'],
       ['5', '9', '6', ..., '8', '6', '8']], 
      dtype='<U21')
>>> Y
array([[1, 4, 4, ..., 4, 3, 4]])
>>> categorical
array([], dtype=float64)
>>> for i in dataset['attributes']:
	print(i)

	
('x-box', 'INTEGER')
('y-box', 'INTEGER')
('width', 'INTEGER')
('high', 'INTEGER')
('onpix', 'INTEGER')
('x-bar', 'INTEGER')
('y-bar', 'INTEGER')
('x2bar', 'INTEGER')
('y2bar', 'INTEGER')
('xybar', 'INTEGER')
('x2ybr', 'INTEGER')
('xy2br', 'INTEGER')
('x-ege', 'INTEGER')
('xegvy', 'INTEGER')
('y-ege', 'INTEGER')
('yegvx', 'INTEGER')
('class', ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'])
>>> X
array([['2', '4', '4', ..., '8', '5', '6'],
       ['4', '7', '5', ..., '9', '7', '10'],
       ['7', '10', '8', ..., '5', '5', '10'],
       ..., 
       ['4', '8', '4', ..., '9', '3', '7'],
       ['4', '11', '4', ..., '8', '0', '8'],
       ['5', '9', '6', ..., '8', '6', '8']], 
      dtype='<U21')
>>> Y
array([[1, 4, 4, ..., 4, 3, 4]])
>>> categorical
array([], dtype=float64)
>>> non_categorical
array([['2', '4', '4', ..., '8', '5', '6'],
       ['4', '7', '5', ..., '9', '7', '10'],
       ['7', '10', '8', ..., '5', '5', '10'],
       ..., 
       ['4', '8', '4', ..., '9', '3', '7'],
       ['4', '11', '4', ..., '8', '0', '8'],
       ['5', '9', '6', ..., '8', '6', '8']], 
      dtype='<U21')
>>> isintancc
Traceback (most recent call last):
  File "<pyshell#272>", line 1, in <module>
    isintancc
NameError: name 'isintancc' is not defined
>>> isinstance(dataset['attributes'][0][1], str)
True
>>> dataset['attributes'][0][1]
'INTEGER'
>>> categorical.shape
(0,)
>>> categorical.shape[0]
0
>>> np.concatenate((categorical, non_categorical))
Traceback (most recent call last):
  File "<pyshell#277>", line 1, in <module>
    np.concatenate((categorical, non_categorical))
ValueError: all the input arrays must have same number of dimensions
>>> np.concatenate((categorical, non_categorical), axis = 1)
Traceback (most recent call last):
  File "<pyshell#278>", line 1, in <module>
    np.concatenate((categorical, non_categorical), axis = 1)
IndexError: axis 1 out of bounds [0, 1)
>>> np.concatenate((categorical, non_categorical), axis = 1)
Traceback (most recent call last):
  File "<pyshell#279>", line 1, in <module>
    np.concatenate((categorical, non_categorical), axis = 1)
IndexError: axis 1 out of bounds [0, 1)

>>> categorical
array([], dtype=float64)
>>> non_categorical
array([['2', '4', '4', ..., '8', '5', '6'],
       ['4', '7', '5', ..., '9', '7', '10'],
       ['7', '10', '8', ..., '5', '5', '10'],
       ..., 
       ['4', '8', '4', ..., '9', '3', '7'],
       ['4', '11', '4', ..., '8', '0', '8'],
       ['5', '9', '6', ..., '8', '6', '8']], 
      dtype='<U21')
>>> transformed_X = np.concatenate((categorical, non_categorical), axis = 1)
Traceback (most recent call last):
  File "<pyshell#282>", line 1, in <module>
    transformed_X = np.concatenate((categorical, non_categorical), axis = 1)
IndexError: axis 1 out of bounds [0, 1)
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
letter.arff
Traceback (most recent call last):
  File "/Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py", line 110, in <module>
    Y = np.array([a], dtype = np.int)
NameError: name 'a' is not defined
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
letter.arff
Traceback (most recent call last):
  File "/Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py", line 140, in <module>
    cv = KFold(10, True, seeds[j])))
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_validation.py", line 342, in cross_val_score
    pre_dispatch=pre_dispatch)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_validation.py", line 206, in cross_validate
    for train, test in cv.split(X, y, groups))
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 779, in __call__
    while self.dispatch_one_batch(iterator):
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 625, in dispatch_one_batch
    self._dispatch(tasks)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 588, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py", line 111, in apply_async
    result = ImmediateResult(func)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py", line 332, in __init__
    self.results = batch()
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 131, in __call__
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 131, in <listcomp>
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_validation.py", line 488, in _fit_and_score
    test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_validation.py", line 523, in _score
    return _multimetric_score(estimator, X_test, y_test, scorer)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_validation.py", line 553, in _multimetric_score
    score = scorer(estimator, X_test, y_test)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/scorer.py", line 101, in __call__
    y_pred = estimator.predict(X)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/neighbors/classification.py", line 145, in predict
    neigh_dist, neigh_ind = self.kneighbors(X)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/neighbors/base.py", line 370, in kneighbors
    if self.effective_metric_ == 'euclidean':
KeyboardInterrupt
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
letter.arff
>>> input_data
array([['2', '4', '4', ..., '5', '6', '25'],
       ['4', '7', '5', ..., '7', '10', '15'],
       ['7', '10', '8', ..., '5', '10', '18'],
       ..., 
       ['4', '8', '4', ..., '3', '7', '14'],
       ['4', '11', '4', ..., '0', '8', '11'],
       ['5', '9', '6', ..., '6', '8', '16']], 
      dtype='<U21')
>>> transformed_X
array([['2', '4', '4', ..., '8', '5', '6'],
       ['4', '7', '5', ..., '9', '7', '10'],
       ['7', '10', '8', ..., '5', '5', '10'],
       ..., 
       ['4', '8', '4', ..., '9', '3', '7'],
       ['4', '11', '4', ..., '8', '0', '8'],
       ['5', '9', '6', ..., '8', '6', '8']], 
      dtype='<U21')
>>> Y
array([[25, 15, 18, ..., 14, 11, 16]])
>>> aa
array([25, 15, 18, ..., 14, 11, 16])
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
anneal.arff
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
anneal.arff
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
audiology.arff
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
autos.arff
0
1
2
3
4
5
6
7
8
9
credit-a.arff
0
1
2
3
4
5
6
7
8
hypothyroid.arff
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
letter.arff
Traceback (most recent call last):
  File "/Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py", line 141, in <module>
    cv = KFold(10, True, seeds[j])))
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_validation.py", line 342, in cross_val_score
    pre_dispatch=pre_dispatch)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_validation.py", line 206, in cross_validate
    for train, test in cv.split(X, y, groups))
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 779, in __call__
    while self.dispatch_one_batch(iterator):
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 625, in dispatch_one_batch
    self._dispatch(tasks)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 588, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py", line 111, in apply_async
    result = ImmediateResult(func)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py", line 332, in __init__
    self.results = batch()
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 131, in __call__
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 131, in <listcomp>
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_validation.py", line 488, in _fit_and_score
    test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_validation.py", line 523, in _score
    return _multimetric_score(estimator, X_test, y_test, scorer)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_validation.py", line 553, in _multimetric_score
    score = scorer(estimator, X_test, y_test)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/scorer.py", line 101, in __call__
    y_pred = estimator.predict(X)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/neighbors/classification.py", line 145, in predict
    neigh_dist, neigh_ind = self.kneighbors(X)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/neighbors/base.py", line 357, in kneighbors
    n_jobs=n_jobs, squared=True)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/pairwise.py", line 1247, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/pairwise.py", line 1090, in _parallel_pairwise
    return func(X, Y, **kwds)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/pairwise.py", line 246, in euclidean_distances
    distances = safe_sparse_dot(X, Y.T, dense_output=True)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/extmath.py", line 140, in safe_sparse_dot
    return np.dot(a, b)
KeyboardInterrupt
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
anneal.arff
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
audiology.arff
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
autos.arff
0
1
2
3
4
5
6
7
8
9
credit-a.arff
0
1
2
3
4
5
6
7
8
hypothyroid.arff
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
vote.arff
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
>>> header = ["{:^123}".format("Nearest Neighbour Results") + '\n' + '-' * 123  + '\n' + \
          "{:^15} | {:^10} | {:^16} | {:^16} | {:^16} | {:^16} | {:^16}" \
          .format("Dataset", "Baseline", "10%", "25%", "50%", "75%", "100%"),
          "{:^123}".format("Decision Tree Results") + '\n' + '-' * 123  + '\n' + \
          "{:^15} | {:^10} | {:^16} | {:^16} | {:^16} | {:^16} | {:^16}" \
          .format("Dataset", "Baseline", "10%", "25%", "50%", "75%", "100%")]
>>> header[0]
'                                                 Nearest Neighbour Results                                                 \n---------------------------------------------------------------------------------------------------------------------------\n    Dataset     |  Baseline  |       10%        |       25%        |       50%        |       75%        |       100%      '
>>> head[1]
Traceback (most recent call last):
  File "<pyshell#289>", line 1, in <module>
    head[1]
NameError: name 'head' is not defined
>>> head[1]
Traceback (most recent call last):
  File "<pyshell#290>", line 1, in <module>
    head[1]
NameError: name 'head' is not defined
>>> header[1]
'                                                   Decision Tree Results                                                   \n---------------------------------------------------------------------------------------------------------------------------\n    Dataset     |  Baseline  |       10%        |       25%        |       50%        |       75%        |       100%      '
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
anneal.arff
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
>>> input_data
array([['1', '0', '0', ..., '610.0', '0.0', '2'],
       ['1', '0', '0', ..., '610.0', '0.0', '2'],
       ['1', '0', '0', ..., '1300.0', '762.0', '2'],
       ..., 
       ['1', '0', '0', ..., '150.0', '762.0', '1'],
       ['1', '0', '0', ..., '20.0', '0.0', '4'],
       ['1', '0', '0', ..., '610.0', '0.0', '4']], 
      dtype='<U21')
>>> transformed_X
array([['1', '0', '0', ..., '0.7', '610.0', '0.0'],
       ['1', '0', '0', ..., '3.2', '610.0', '0.0'],
       ['1', '0', '0', ..., '0.7', '1300.0', '762.0'],
       ..., 
       ['1', '0', '0', ..., '1.599', '150.0', '762.0'],
       ['1', '0', '0', ..., '0.4', '20.0', '0.0'],
       ['1', '0', '0', ..., '4.0', '610.0', '0.0']], 
      dtype='<U11')
>>> Y
array([[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2,
        4, 2, 0, 2, 2, 2, 2, 2, 3, 2, 2, 4, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2,
        3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2,
        3, 1, 2, 3, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2,
        1, 3, 4, 2, 2, 2, 2, 2, 1, 3, 3, 1, 1, 2, 2, 2, 2, 2, 2, 3, 2, 2,
        2, 2, 3, 2, 2, 1, 4, 2, 2, 0, 2, 2, 2, 2, 2, 3, 2, 3, 1, 1, 2, 2,
        1, 1, 2, 1, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2,
        2, 2, 2, 4, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 1, 2,
        2, 2, 2, 1, 4, 3, 2, 2, 2, 2, 2, 2, 0, 4, 2, 3, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2,
        2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 2,
        2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 1, 1, 2,
        2, 3, 2, 4, 2, 2, 2, 2, 2, 2, 2, 3, 4, 1, 0, 2, 2, 1, 2, 1, 2, 2,
        2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 1, 3, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2,
        2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2,
        4, 2, 2, 2, 2, 4, 3, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        1, 3, 2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 0, 2, 4, 2, 2, 3, 2, 4, 2, 3,
        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1,
        2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 0, 1, 2, 1, 2, 1, 4, 3, 2, 2, 2, 2,
        2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 4, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1,
        2, 1, 2, 3, 2, 2, 1, 2, 2, 2, 2, 2, 2, 4, 2, 1, 2, 1, 3, 3, 2, 2,
        2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 2, 3, 2, 2, 3, 2, 2, 2,
        4, 4, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 1, 4,
        2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 3, 1, 2,
        2, 3, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 1,
        2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 4, 2,
        2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 3, 2, 2, 2, 4,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1,
        2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 3, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,
        2, 2, 1, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 1, 2, 2, 2, 4, 3,
        1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 3, 2, 1, 2, 2, 2, 2, 3, 2, 2, 3,
        2, 2, 3, 1, 3, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2,
        1, 2, 1, 2, 2, 4, 2, 2, 1, 2, 3, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2,
        2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 1, 2, 2,
        2, 3, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 3, 2, 2,
        2, 2, 2, 2, 2, 1, 2, 2, 4, 2, 2, 3, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2,
        2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2,
        2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 1, 3, 1, 1, 1, 4, 4]])
>>> Y.T
array([[2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [4],
       [4],
       [2],
       [2],
       [2],
       [2],
       [4],
       [2],
       [0],
       [2],
       [2],
       [2],
       [2],
       [2],
       [3],
       [2],
       [2],
       [4],
       [2],
       [3],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [3],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [4],
       [2],
       [2],
       [3],
       [1],
       [2],
       [3],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [1],
       [2],
       [1],
       [3],
       [4],
       [2],
       [2],
       [2],
       [2],
       [2],
       [1],
       [3],
       [3],
       [1],
       [1],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [3],
       [2],
       [2],
       [2],
       [2],
       [3],
       [2],
       [2],
       [1],
       [4],
       [2],
       [2],
       [0],
       [2],
       [2],
       [2],
       [2],
       [2],
       [3],
       [2],
       [3],
       [1],
       [1],
       [2],
       [2],
       [1],
       [1],
       [2],
       [1],
       [2],
       [2],
       [3],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [1],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [4],
       [3],
       [2],
       [3],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [3],
       [2],
       [2],
       [3],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [1],
       [4],
       [3],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [0],
       [4],
       [2],
       [3],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [1],
       [2],
       [1],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [3],
       [2],
       [2],
       [2],
       [3],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [3],
       [3],
       [2],
       [2],
       [1],
       [1],
       [2],
       [2],
       [3],
       [2],
       [4],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [3],
       [4],
       [1],
       [0],
       [2],
       [2],
       [1],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [0],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [1],
       [3],
       [2],
       [2],
       [2],
       [2],
       [1],
       [1],
       [2],
       [2],
       [2],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [3],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [4],
       [2],
       [2],
       [2],
       [2],
       [4],
       [3],
       [2],
       [2],
       [2],
       [2],
       [0],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [1],
       [3],
       [2],
       [2],
       [2],
       [2],
       [4],
       [2],
       [4],
       [2],
       [2],
       [2],
       [0],
       [2],
       [4],
       [2],
       [2],
       [3],
       [2],
       [4],
       [2],
       [3],
       [1],
       [1],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [4],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [1],
       [1],
       [2],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [1],
       [2],
       [1],
       [0],
       [1],
       [2],
       [1],
       [2],
       [1],
       [4],
       [3],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [4],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [1],
       [2],
       [1],
       [2],
       [3],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [4],
       [2],
       [1],
       [2],
       [1],
       [3],
       [3],
       [2],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [3],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [4],
       [2],
       [2],
       [4],
       [2],
       [3],
       [2],
       [2],
       [3],
       [2],
       [2],
       [2],
       [4],
       [4],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [3],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [1],
       [4],
       [2],
       [2],
       [3],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [1],
       [2],
       [2],
       [1],
       [1],
       [2],
       [2],
       [3],
       [1],
       [2],
       [2],
       [3],
       [2],
       [2],
       [2],
       [1],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [3],
       [2],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [2],
       [4],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [1],
       [2],
       [1],
       [2],
       [2],
       [2],
       [4],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [2],
       [3],
       [2],
       [2],
       [2],
       [3],
       [2],
       [3],
       [2],
       [2],
       [2],
       [4],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [4],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [1],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [2],
       [1],
       [2],
       [3],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [3],
       [2],
       [2],
       [2],
       [3],
       [2],
       [2],
       [2],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [4],
       [3],
       [1],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [1],
       [2],
       [2],
       [1],
       [3],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [3],
       [2],
       [2],
       [3],
       [2],
       [2],
       [3],
       [1],
       [3],
       [2],
       [2],
       [2],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [2],
       [4],
       [2],
       [2],
       [2],
       [2],
       [2],
       [1],
       [2],
       [1],
       [2],
       [2],
       [4],
       [2],
       [2],
       [1],
       [2],
       [3],
       [2],
       [2],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [3],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [3],
       [2],
       [1],
       [2],
       [2],
       [2],
       [3],
       [2],
       [2],
       [2],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [1],
       [3],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [1],
       [2],
       [2],
       [4],
       [2],
       [2],
       [3],
       [1],
       [1],
       [2],
       [2],
       [2],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [3],
       [3],
       [2],
       [2],
       [2],
       [2],
       [3],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [4],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [2],
       [1],
       [2],
       [4],
       [2],
       [4],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [3],
       [3],
       [1],
       [3],
       [1],
       [1],
       [1],
       [4],
       [4]])
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
letter.arff
>>> input_data
array([['2', '4', '4', ..., '5', '6', '25'],
       ['4', '7', '5', ..., '7', '10', '15'],
       ['7', '10', '8', ..., '5', '10', '18'],
       ..., 
       ['4', '8', '4', ..., '3', '7', '14'],
       ['4', '11', '4', ..., '0', '8', '11'],
       ['5', '9', '6', ..., '6', '8', '16']], 
      dtype='<U21')
>>> array([['1', '0', '0', ..., '610.0', '0.0', '2'],
       ['1', '0', '0', ..., '610.0', '0.0', '2'],
       ['1', '0', '0', ..., '1300.0', '762.0', '2'],
       ..., 
       ['1', '0', '0', ..., '150.0', '762.0', '1'],
       ['1', '0', '0', ..., '20.0', '0.0', '4'],
       ['1', '0', '0', ..., '610.0', '0.0', '4']], 
      dtype='<U21')
Traceback (most recent call last):
  File "<pyshell#297>", line 1, in <module>
    array([['1', '0', '0', ..., '610.0', '0.0', '2'],
NameError: name 'array' is not defined
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
letter.arff
here
>>> transformed_X
array([['2', '4', '4', ..., '8', '5', '6'],
       ['4', '7', '5', ..., '9', '7', '10'],
       ['7', '10', '8', ..., '5', '5', '10'],
       ..., 
       ['4', '8', '4', ..., '9', '3', '7'],
       ['4', '11', '4', ..., '8', '0', '8'],
       ['5', '9', '6', ..., '8', '6', '8']], 
      dtype='<U21')
>>> Y
array([[25, 15, 18, ..., 14, 11, 16]])
>>> input_data
array([['2', '4', '4', ..., '5', '6', '25'],
       ['4', '7', '5', ..., '7', '10', '15'],
       ['7', '10', '8', ..., '5', '10', '18'],
       ..., 
       ['4', '8', '4', ..., '3', '7', '14'],
       ['4', '11', '4', ..., '0', '8', '11'],
       ['5', '9', '6', ..., '6', '8', '16']], 
      dtype='<U21')
>>> data[0]
array(['2', '4', '4', '3', '2', '7', '8', '2', '9', '11', '7', '7', '1',
       '8', '5', '6', 'Z'], 
      dtype='<U21')
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
letter.arff
here
>>> sample
[array([['5', '8', '7', ..., '7', '9', '2'],
       ['1', '0', '2', ..., '7', '8', '18'],
       ['2', '6', '3', ..., '0', '8', '9'],
       ..., 
       ['2', '4', '3', ..., '3', '8', '7'],
       ['2', '1', '2', ..., '3', '8', '16'],
       ['5', '9', '7', ..., '8', '9', '4']], 
      dtype='<U21'), None, None, None, None, None, None, None, None, None, None]
>>> len(sample)
11
>>> sample[0]
array([['5', '8', '7', ..., '7', '9', '2'],
       ['1', '0', '2', ..., '7', '8', '18'],
       ['2', '6', '3', ..., '0', '8', '9'],
       ..., 
       ['2', '4', '3', ..., '3', '8', '7'],
       ['2', '1', '2', ..., '3', '8', '16'],
       ['5', '9', '7', ..., '8', '9', '4']], 
      dtype='<U21')
>>> sample[1]
>>> sample[2]
>>> sample[0]
array([['5', '8', '7', ..., '7', '9', '2'],
       ['1', '0', '2', ..., '7', '8', '18'],
       ['2', '6', '3', ..., '0', '8', '9'],
       ..., 
       ['2', '4', '3', ..., '3', '8', '7'],
       ['2', '1', '2', ..., '3', '8', '16'],
       ['5', '9', '7', ..., '8', '9', '4']], 
      dtype='<U21')
>>> for i in sample"
SyntaxError: EOL while scanning string literal
>>> for i in sample"
SyntaxError: EOL while scanning string literal
>>> for i in sample:
	print(i)

	
[['5' '8' '7' ..., '7' '9' '2']
 ['1' '0' '2' ..., '7' '8' '18']
 ['2' '6' '3' ..., '0' '8' '9']
 ..., 
 ['2' '4' '3' ..., '3' '8' '7']
 ['2' '1' '2' ..., '3' '8' '16']
 ['5' '9' '7' ..., '8' '9' '4']]
None
None
None
None
None
None
None
None
None
None
>>> sample[0]
array([['5', '8', '7', ..., '7', '9', '2'],
       ['1', '0', '2', ..., '7', '8', '18'],
       ['2', '6', '3', ..., '0', '8', '9'],
       ..., 
       ['2', '4', '3', ..., '3', '8', '7'],
       ['2', '1', '2', ..., '3', '8', '16'],
       ['5', '9', '7', ..., '8', '9', '4']], 
      dtype='<U21')
>>> sample[1]
>>> sample[2]
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
letter.arff
here
>>> score
[0.038699999999999998, 0.037649999999999996, 0.036749999999999998, 0.037299999999999993, 0.036850000000000008, 0.036749999999999998, 0.037949999999999998, 0.038099999999999995, 0.037850000000000009, 0.036199999999999996]
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
letter.arff
here
0
1
2
3
4
5
6
7
8
9
10
                                                 Nearest Neighbour Results                                                 
---------------------------------------------------------------------------------------------------------------------------
    Dataset     |  Baseline  |       10%        |       25%        |       50%        |       75%        |       100%      
letter          |     96.26% | 16.86% (0.35%) * |  9.61% (0.20%) * |  6.05% (0.08%) * |  4.71% (0.06%) * |  3.93% (0.07%) *
Traceback (most recent call last):
  File "/Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py", line 147, in <module>
    scores = score_list[i][1]
IndexError: list index out of range
>>> sample
[array([['5', '8', '7', ..., '7', '9', '2'],
       ['1', '0', '2', ..., '7', '8', '18'],
       ['2', '6', '3', ..., '0', '8', '9'],
       ..., 
       ['2', '4', '3', ..., '3', '8', '7'],
       ['2', '1', '2', ..., '3', '8', '16'],
       ['5', '9', '7', ..., '8', '9', '4']], 
      dtype='<U21'), array([['4', '6', '6', ..., '9', '8', '1'],
       ['4', '8', '6', ..., '9', '9', '8'],
       ['5', '9', '7', ..., '3', '7', '13'],
       ..., 
       ['3', '4', '4', ..., '2', '5', '19'],
       ['4', '9', '4', ..., '3', '8', '14'],
       ['4', '5', '7', ..., '3', '7', '7']], 
      dtype='<U21'), array([['4', '9', '6', ..., '5', '8', '1'],
       ['5', '11', '6', ..., '4', '8', '15'],
       ['5', '7', '6', ..., '7', '11', '5'],
       ..., 
       ['4', '6', '5', ..., '0', '8', '12'],
       ['4', '6', '6', ..., '3', '8', '14'],
       ['3', '7', '5', ..., '6', '4', '25']], 
      dtype='<U21'), array([['4', '5', '5', ..., '4', '8', '23'],
       ['4', '10', '7', ..., '8', '6', '23'],
       ['5', '11', '5', ..., '7', '6', '4'],
       ..., 
       ['6', '10', '8', ..., '4', '8', '10'],
       ['6', '14', '5', ..., '5', '8', '8'],
       ['3', '3', '4', ..., '8', '9', '1']], 
      dtype='<U21'), array([['1', '3', '3', ..., '5', '7', '25'],
       ['2', '2', '3', ..., '7', '8', '25'],
       ['3', '6', '4', ..., '6', '8', '23'],
       ..., 
       ['2', '3', '3', ..., '2', '8', '14'],
       ['4', '9', '7', ..., '3', '9', '0'],
       ['4', '6', '5', ..., '5', '10', '17']], 
      dtype='<U21'), array([['4', '9', '5', ..., '4', '8', '8'],
       ['5', '10', '6', ..., '4', '8', '23'],
       ['5', '6', '7', ..., '5', '6', '3'],
       ..., 
       ['2', '2', '3', ..., '5', '10', '16'],
       ['4', '6', '4', ..., '0', '8', '20'],
       ['3', '6', '4', ..., '3', '8', '14']], 
      dtype='<U21'), array([['7', '9', '10', ..., '4', '4', '10'],
       ['3', '9', '4', ..., '3', '9', '14'],
       ['4', '9', '5', ..., '2', '6', '11'],
       ..., 
       ['4', '9', '5', ..., '3', '7', '3'],
       ['5', '5', '6', ..., '2', '11', '10'],
       ['1', '0', '2', ..., '6', '8', '25']], 
      dtype='<U21'), array([['5', '11', '8', ..., '4', '9', '0'],
       ['3', '7', '5', ..., '3', '5', '5'],
       ['2', '5', '4', ..., '1', '7', '9'],
       ..., 
       ['4', '10', '4', ..., '0', '8', '7'],
       ['5', '8', '6', ..., '5', '9', '16'],
       ['2', '0', '2', ..., '5', '10', '6']], 
      dtype='<U21'), array([['3', '5', '4', ..., '7', '7', '4'],
       ['3', '5', '5', ..., '4', '8', '4'],
       ['3', '4', '5', ..., '3', '9', '17'],
       ..., 
       ['12', '14', '12', ..., '1', '6', '22'],
       ['2', '5', '4', ..., '2', '8', '15'],
       ['7', '11', '10', ..., '2', '7', '5']], 
      dtype='<U21'), array([['2', '4', '4', ..., '0', '8', '24'],
       ['6', '10', '6', ..., '3', '7', '2'],
       ['2', '5', '4', ..., '3', '8', '11'],
       ..., 
       ['4', '9', '6', ..., '4', '9', '14'],
       ['4', '8', '6', ..., '5', '6', '20'],
       ['6', '11', '6', ..., '2', '4', '19']], 
      dtype='<U21'), array([['3', '5', '6', ..., '5', '10', '4'],
       ['0', '8', '0', ..., '0', '8', '8'],
       ['2', '3', '2', ..., '4', '8', '16'],
       ..., 
       ['5', '7', '7', ..., '9', '7', '9'],
       ['8', '11', '11', ..., '5', '10', '7'],
       ['5', '11', '7', ..., '3', '7', '3']], 
      dtype='<U21')]
>>> import pandas as pd
>>> testdata = pd.DataFrame({'pet': ['cat', 'dog', 'dog', 'fish'],'age': [4 , 6, 3, 3],
'salary':[4, 5, 1, 1]})
>>> testdata
   age   pet  salary
0    4   cat       4
1    6   dog       5
2    3   dog       1
3    3  fish       1
>>> a1 = OneHotEncoder(sparse = False).fit_transform( testdata[['age']] )
>>> a2 = OneHotEncoder(sparse = False).fit_transform( testdata[['salary']])
>>> a1
array([[ 0.,  1.,  0.],
       [ 0.,  0.,  1.],
       [ 1.,  0.,  0.],
       [ 1.,  0.,  0.]])
>>> a2
array([[ 0.,  1.,  0.],
       [ 0.,  0.,  1.],
       [ 1.,  0.,  0.],
       [ 1.,  0.,  0.]])
>>> final_output = numpy.hstack((a1,a2))
Traceback (most recent call last):
  File "<pyshell#325>", line 1, in <module>
    final_output = numpy.hstack((a1,a2))
NameError: name 'numpy' is not defined
>>> import numpy
>>> final_output = numpy.hstack((a1,a2))
>>> fian
Traceback (most recent call last):
  File "<pyshell#328>", line 1, in <module>
    fian
NameError: name 'fian' is not defined
>>> final_output
array([[ 0.,  1.,  0.,  0.,  1.,  0.],
       [ 0.,  0.,  1.,  0.,  0.,  1.],
       [ 1.,  0.,  0.,  1.,  0.,  0.],
       [ 1.,  0.,  0.,  1.,  0.,  0.]])
>>> a = LabelEncoder().fit_transform(testdata['pet'])
>>> a
array([0, 1, 1, 2])
>>> OneHotEncoder( sparse=False ).fit_transform(a.reshape(-1,1))
array([[ 1.,  0.,  0.],
       [ 0.,  1.,  0.],
       [ 0.,  1.,  0.],
       [ 0.,  0.,  1.]])
>>> categorical
array([], dtype=float64)
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
anneal.arff
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
>>> input_data
array([['1', '0', '0', ..., '610.0', '0.0', '2'],
       ['1', '0', '0', ..., '610.0', '0.0', '2'],
       ['1', '0', '0', ..., '1300.0', '762.0', '2'],
       ..., 
       ['1', '0', '0', ..., '150.0', '762.0', '1'],
       ['1', '0', '0', ..., '20.0', '0.0', '4'],
       ['1', '0', '0', ..., '610.0', '0.0', '4']], 
      dtype='<U21')
>>> non_categorical
array([['8.0', '0.0', '0.0', '0.7', '610.0', '0.0'],
       ['0.0', '0.0', '0.0', '3.2', '610.0', '0.0'],
       ['0.0', '0.0', '0.0', '0.7', '1300.0', '762.0'],
       ..., 
       ['0.0', '0.0', '0.0', '1.599', '150.0', '762.0'],
       ['0.0', '85.0', '0.0', '0.4', '20.0', '0.0'],
       ['0.0', '85.0', '0.0', '4.0', '610.0', '0.0']], 
      dtype='<U6')
>>> conte
Traceback (most recent call last):
  File "<pyshell#336>", line 1, in <module>
    conte
NameError: name 'conte' is not defined
>>> categorical
array([[1, 0, 0, ..., 0, 0, 1],
       [1, 0, 0, ..., 0, 0, 1],
       [1, 0, 0, ..., 0, 0, 1],
       ..., 
       [1, 0, 0, ..., 0, 0, 1],
       [1, 0, 0, ..., 0, 0, 1],
       [1, 0, 0, ..., 0, 0, 1]], dtype=int32)
>>> non_categorical
array([['8.0', '0.0', '0.0', '0.7', '610.0', '0.0'],
       ['0.0', '0.0', '0.0', '3.2', '610.0', '0.0'],
       ['0.0', '0.0', '0.0', '0.7', '1300.0', '762.0'],
       ..., 
       ['0.0', '0.0', '0.0', '1.599', '150.0', '762.0'],
       ['0.0', '85.0', '0.0', '0.4', '20.0', '0.0'],
       ['0.0', '85.0', '0.0', '4.0', '610.0', '0.0']], 
      dtype='<U6')
>>> input_data[0]
array(['1', '0', '0', '1', '0', '1', '0', '0', '0', '0', '0', '0', '1',
       '0', '0', '0', '1', '0', '0', '0', '0', '1', '1', '0', '1', '0',
       '0', '0', '0', '0', '1', '0', '0', '1', '1', '0', '1', '0', '1',
       '0', '1', '0', '0', '1', '0', '1', '1', '0', '1', '0', '1', '0',
       '1', '1', '0', '1', '0', '1', '1', '0', '0', '0', '1', '0', '1',
       '1', '1', '1', '0', '1', '0', '0', '1', '0', '0', '0', '0', '1',
       '8.0', '0.0', '0.0', '0.7', '610.0', '0.0', '2'], 
      dtype='<U21')
>>> categorical[0]
array([1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,
       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,
       1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0,
       1, 0, 0, 1, 0, 0, 0, 0, 1], dtype=int32)
>>> non_categorical[0]
array(['8.0', '0.0', '0.0', '0.7', '610.0', '0.0'], 
      dtype='<U6')
>>> header = ["{:^123}".format("Nearest Neighbour Results") + '\n' + '-' * 123  + '\n' + \
          "{:^15} | {:^10} | {:^16} | {:^16} | {:^16} | {:^16} | {:^16}" \
          .format("Dataset", "Baseline", "10%", "25%", "50%", "75%", "100%"),
          "{:^123}".format("Decision Tree Results") + '\n' + '-' * 123  + '\n' + \
          "{:^15} | {:^10} | {:^16} | {:^16} | {:^16} | {:^16} | {:^16}" \
          .format("Dataset", "Baseline", "10%", "25%", "50%", "75%", "100%")]
>>> print(header[0])
                                                 Nearest Neighbour Results                                                 
---------------------------------------------------------------------------------------------------------------------------
    Dataset     |  Baseline  |       10%        |       25%        |       50%        |       75%        |       100%      
>>> print(header[1])
                                                   Decision Tree Results                                                   
---------------------------------------------------------------------------------------------------------------------------
    Dataset     |  Baseline  |       10%        |       25%        |       50%        |       75%        |       100%      
>>> score_list
[]
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
anneal.arff
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
>>> 
 RESTART: /Users/marktoms/Desktop/9417/Machine-Learning-And-Data-Mining/Assignment1/datasets/q1.py 
anneal.arff
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
0
1
2
3
4
5
6
7
8
9
10
audiology.arff
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
0
1
2
3
4
5
6
7
8
9
10
autos.arff
0
1
2
3
4
5
6
7
8
9
0
1
2
3
4
5
6
7
8
9
10
credit-a.arff
0
1
2
3
4
5
6
7
8
0
1
2
3
4
5
6
7
8
9
10
hypothyroid.arff
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
0
1
2
3
4
5
6
7
8
9
10
letter.arff
here
0
1
2
3
4
5
6
7
8
9
10
microarray.arff
here
0
1
2
3
4
5
6
7
8
9
10
vote.arff
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
0
1
2
3
4
5
6
7
8
9
10
                                                 Nearest Neighbour Results                                                 
---------------------------------------------------------------------------------------------------------------------------
    Dataset     |  Baseline  |       10%        |       25%        |       50%        |       75%        |       100%      
anneal          |     23.83% | 20.31% (0.94%) * | 18.00% (1.33%) * | 11.32% (0.72%) * |  9.11% (0.37%) * |  7.44% (0.44%) *
audiology       |     74.77% | 60.17% (2.17%) * | 42.00% (2.56%) * | 31.85% (2.13%) * | 29.62% (1.78%) * | 26.47% (1.81%) *
autos           |     67.35% | 64.50% (1.50%) * | 61.40% (2.21%) * | 65.96% (2.02%)   | 52.92% (2.39%) * | 57.37% (0.95%) *
credit-a        |     44.49% | 39.98% (1.05%) * | 41.35% (0.99%) * | 32.04% (1.50%) * | 34.63% (0.79%) * | 34.71% (0.73%) *
hypothyroid     |      7.71% |  8.27% (0.52%) * |  7.33% (0.18%) * |  4.74% (0.14%) * |  5.01% (0.13%) * |  4.79% (0.10%) *
letter          |     96.26% | 16.86% (0.35%) * |  9.61% (0.20%) * |  6.05% (0.08%) * |  4.71% (0.06%) * |  3.93% (0.07%) *
microarray      |     50.20% | 59.47% (2.55%) * | 49.58% (2.36%)   | 42.45% (0.83%) * | 50.71% (0.95%)   | 50.88% (0.60%)  
vote            |     38.63% |  6.45% (1.01%) * | 10.42% (1.16%) * |  8.26% (0.55%) * |  7.12% (0.19%) * |  7.91% (0.39%) *

                                                   Decision Tree Results                                                   
---------------------------------------------------------------------------------------------------------------------------
    Dataset     |  Baseline  |       10%        |       25%        |       50%        |       75%        |       100%      
anneal          |     23.83% |  8.75% (1.60%) * |  4.05% (0.75%) * |  1.49% (0.41%) * |  1.35% (0.24%) * |  0.69% (0.21%) *
audiology       |     74.77% | 61.67% (3.25%) * | 46.63% (5.54%) * | 29.84% (2.47%) * | 21.99% (2.33%) * | 23.10% (1.67%) *
autos           |     67.35% | 74.50% (6.87%) * | 47.77% (6.75%) * | 34.29% (3.31%) * | 29.32% (3.17%) * | 20.97% (2.84%) *
credit-a        |     44.49% | 19.07% (1.87%) * | 12.74% (1.36%) * | 19.96% (1.93%) * | 19.30% (1.49%) * | 19.43% (1.00%) *
hypothyroid     |      7.71% |  2.79% (0.48%) * |  1.55% (0.24%) * |  0.63% (0.05%) * |  0.75% (0.13%) * |  0.60% (0.06%) *
letter          |     96.26% | 28.80% (0.34%) * | 21.57% (0.56%) * | 16.45% (0.23%) * | 13.31% (0.13%) * | 11.80% (0.17%) *
microarray      |     50.20% | 50.67% (4.64%)   | 52.25% (2.80%)   | 51.43% (1.86%)   | 46.39% (1.58%) * | 48.87% (1.43%)  
vote            |     38.63% | 13.95% (3.22%) * |  5.62% (1.31%) * |  6.91% (1.07%) * |  3.31% (0.40%) * |  5.91% (0.60%) *

>>> score_list
[('anneal', array([[ 0.23817728,  0.23830212,  0.23827715,  0.23830212,  0.23831461,
         0.23822722,  0.23830212,  0.2382397 ,  0.23833958,  0.23830212],
       [ 0.20138889,  0.19166667,  0.2125    ,  0.20416667,  0.20138889,
         0.20138889,  0.225     ,  0.20138889,  0.19027778,  0.20138889],
       [ 0.16581028,  0.17391304,  0.19150198,  0.16185771,  0.16403162,
         0.18300395,  0.19189723,  0.19209486,  0.20177866,  0.1743083 ],
       [ 0.12474747,  0.10459596,  0.11368687,  0.10469697,  0.11141414,
         0.12020202,  0.10691919,  0.11146465,  0.12459596,  0.10919192],
       [ 0.08773047,  0.09506146,  0.08775241,  0.09062774,  0.08770852,
         0.09352502,  0.09962687,  0.08920105,  0.08933275,  0.090518  ],
       [ 0.08357054,  0.07566792,  0.07122347,  0.07681648,  0.07233458,
         0.0690387 ,  0.07575531,  0.07790262,  0.07353308,  0.06791511],
       [ 0.05555556,  0.09027778,  0.1125    ,  0.08888889,  0.07916667,
         0.07777778,  0.07777778,  0.1125    ,  0.09027778,  0.09027778],
       [ 0.04051383,  0.03992095,  0.0444664 ,  0.02213439,  0.0527668 ,
         0.04525692,  0.0444664 ,  0.04011858,  0.03577075,  0.03992095],
       [ 0.01343434,  0.02449495,  0.00893939,  0.01338384,  0.01111111,
         0.01555556,  0.01777778,  0.01787879,  0.01333333,  0.01333333],
       [ 0.01488147,  0.01035996,  0.01191835,  0.01483758,  0.01483758,
         0.01336699,  0.0178007 ,  0.00891133,  0.01485953,  0.01338894],
       [ 0.00667915,  0.00555556,  0.00558052,  0.0111236 ,  0.00444444,
         0.00666667,  0.00444444,  0.00780275,  0.01      ,  0.00669164]])), ('audiology', array([[ 0.74822134,  0.74743083,  0.74762846,  0.74762846,  0.7472332 ,
         0.7486166 ,  0.74703557,  0.74822134,  0.74782609,  0.7472332 ],
       [ 0.61666667,  0.6       ,  0.6       ,  0.56666667,  0.65      ,
         0.58333333,  0.58333333,  0.6       ,  0.6       ,  0.61666667],
       [ 0.45666667,  0.38333333,  0.39      ,  0.42333333,  0.43      ,
         0.41      ,  0.39666667,  0.40666667,  0.45333333,  0.45      ],
       [ 0.30681818,  0.30151515,  0.31742424,  0.30075758,  0.30075758,
         0.3030303 ,  0.36136364,  0.34848485,  0.33787879,  0.30681818],
       [ 0.28897059,  0.28933824,  0.30147059,  0.31286765,  0.27904412,
         0.27867647,  0.33014706,  0.27867647,  0.28345588,  0.31911765],
       [ 0.26936759,  0.30434783,  0.24802372,  0.24328063,  0.25177866,
         0.2527668 ,  0.26620553,  0.26106719,  0.28913043,  0.26126482],
       [ 0.58333333,  0.58333333,  0.63333333,  0.65      ,  0.6       ,
         0.65      ,  0.56666667,  0.66666667,  0.63333333,  0.6       ],
       [ 0.45      ,  0.49333333,  0.41      ,  0.42666667,  0.59333333,
         0.48333333,  0.41      ,  0.48666667,  0.40666667,  0.50333333],
       [ 0.26363636,  0.30151515,  0.33484848,  0.30151515,  0.32878788,
         0.30984848,  0.29469697,  0.26666667,  0.26515152,  0.31742424],
       [ 0.17720588,  0.24889706,  0.19411765,  0.20110294,  0.25477941,
         0.21801471,  0.225     ,  0.21911765,  0.24227941,  0.21838235],
       [ 0.23379447,  0.22608696,  0.23833992,  0.21679842,  0.21225296,
         0.26581028,  0.2256917 ,  0.22549407,  0.25355731,  0.21205534]])), ('autos', array([[ 0.67428571,  0.67357143,  0.67452381,  0.67357143,  0.67380952,
         0.67333333,  0.67309524,  0.67309524,  0.67333333,  0.67261905],
       [ 0.65      ,  0.65      ,  0.65      ,  0.6       ,  0.65      ,
         0.65      ,  0.65      ,  0.65      ,  0.65      ,  0.65      ],
       [ 0.59      ,  0.64666667,  0.61      ,  0.58333333,  0.65      ,
         0.63333333,  0.61333333,  0.61333333,  0.59      ,  0.61      ],
       [ 0.66727273,  0.66818182,  0.64181818,  0.66636364,  0.63818182,
         0.68636364,  0.63818182,  0.68636364,  0.67545455,  0.62818182],
       [ 0.53416667,  0.49541667,  0.54708333,  0.53791667,  0.50916667,
         0.53416667,  0.53      ,  0.52791667,  0.58041667,  0.49583333],
       [ 0.5802381 ,  0.57547619,  0.57047619,  0.57142857,  0.57142857,
         0.56595238,  0.555     ,  0.585     ,  0.57071429,  0.59095238],
       [ 0.85      ,  0.7       ,  0.8       ,  0.8       ,  0.7       ,
         0.65      ,  0.7       ,  0.7       ,  0.7       ,  0.85      ],
       [ 0.40666667,  0.50666667,  0.57      ,  0.41666667,  0.59      ,
         0.41      ,  0.38666667,  0.50666667,  0.51      ,  0.47333333],
       [ 0.29272727,  0.33363636,  0.35363636,  0.36545455,  0.33545455,
         0.33272727,  0.39090909,  0.36      ,  0.38090909,  0.28363636],
       [ 0.31958333,  0.28666667,  0.34583333,  0.28083333,  0.31875   ,
         0.26916667,  0.31916667,  0.22875   ,  0.28791667,  0.27583333],
       [ 0.17190476,  0.20952381,  0.24357143,  0.2002381 ,  0.1852381 ,
         0.1997619 ,  0.20547619,  0.195     ,  0.27666667,  0.21      ]])), ('credit-a', array([[ 0.44492754,  0.44492754,  0.44492754,  0.44492754,  0.44492754,
         0.44492754,  0.44492754,  0.44492754,  0.44492754,  0.44492754],
       [ 0.39047619,  0.40714286,  0.41428571,  0.39285714,  0.40238095,
         0.40714286,  0.40714286,  0.40714286,  0.39047619,  0.37857143],
       [ 0.41405229,  0.41830065,  0.4127451 ,  0.41862745,  0.40196078,
         0.40718954,  0.41830065,  0.40098039,  0.40653595,  0.43660131],
       [ 0.32260504,  0.30773109,  0.34210084,  0.33243697,  0.31310924,
         0.3197479 ,  0.33310924,  0.31571429,  0.3305042 ,  0.28672269],
       [ 0.35399698,  0.33883861,  0.35995475,  0.34611614,  0.35196078,
         0.34264706,  0.34992459,  0.33842383,  0.33242836,  0.3484917 ],
       [ 0.34637681,  0.33623188,  0.35217391,  0.36086957,  0.34057971,
         0.33913043,  0.35217391,  0.34782609,  0.35362319,  0.34202899],
       [ 0.17619048,  0.21666667,  0.20238095,  0.21428571,  0.17619048,
         0.15714286,  0.20238095,  0.17380952,  0.20238095,  0.18571429],
       [ 0.11633987,  0.11633987,  0.12777778,  0.13333333,  0.15196078,
         0.11568627,  0.12908497,  0.10424837,  0.13921569,  0.14019608],
       [ 0.19134454,  0.18848739,  0.21420168,  0.20571429,  0.1910084 ,
         0.24630252,  0.20588235,  0.17352941,  0.19705882,  0.18226891],
       [ 0.22435897,  0.1974359 ,  0.17586727,  0.18012821,  0.18374811,
         0.18382353,  0.21466817,  0.18736802,  0.19739819,  0.18563348],
       [ 0.1942029 ,  0.1884058 ,  0.2       ,  0.2       ,  0.20869565,
         0.17681159,  0.21014493,  0.19275362,  0.1884058 ,  0.18405797]])), ('hypothyroid', array([[ 0.07715254,  0.07714693,  0.07714903,  0.07714202,  0.07714623,
         0.07715465,  0.0771378 ,  0.07714272,  0.07714412,  0.07714693],
       [ 0.07411095,  0.07688478,  0.08207681,  0.08990043,  0.09039829,
         0.07951636,  0.08492176,  0.07951636,  0.08776671,  0.08200569],
       [ 0.07529675,  0.07530795,  0.07638298,  0.07209406,  0.07315789,
         0.07212766,  0.0731467 ,  0.0700112 ,  0.0731355 ,  0.07210526],
       [ 0.04877012,  0.04719408,  0.04823258,  0.04932737,  0.04823821,
         0.04718001,  0.04403918,  0.04613025,  0.04771755,  0.04716593],
       [ 0.04842368,  0.0491329 ,  0.04983836,  0.05125554,  0.05090093,
         0.04879332,  0.04984086,  0.05302108,  0.05054257,  0.0491329 ],
       [ 0.0477229 ,  0.04692364,  0.04771799,  0.04665839,  0.04772501,
         0.04824709,  0.04984632,  0.0487804 ,  0.04904074,  0.04666189],
       [ 0.02674253,  0.0185633 ,  0.02660028,  0.02645804,  0.02660028,
         0.03456615,  0.03698435,  0.02638691,  0.02645804,  0.02916074],
       [ 0.01802912,  0.01167973,  0.01380739,  0.01697648,  0.01905935,
         0.01592385,  0.01801792,  0.01378499,  0.01273236,  0.01486002],
       [ 0.00529945,  0.00635202,  0.00583136,  0.00688675,  0.00635765,
         0.00688956,  0.00636328,  0.00689238,  0.00636609,  0.00583136],
       [ 0.00742676,  0.00671629,  0.00671754,  0.00636418,  0.00777385,
         0.00565496,  0.00848432,  0.00883643,  0.01025111,  0.00636168],
       [ 0.00556748,  0.00582923,  0.00689234,  0.00530223,  0.00715759,
         0.00662849,  0.00556748,  0.00636043,  0.00556748,  0.00556468]])), ('letter', array([[ 0.9613    ,  0.96235   ,  0.96325   ,  0.9627    ,  0.96315   ,
         0.96325   ,  0.96205   ,  0.9619    ,  0.96215   ,  0.9638    ],
       [ 0.165     ,  0.173     ,  0.162     ,  0.1725    ,  0.171     ,
         0.171     ,  0.169     ,  0.1645    ,  0.1675    ,  0.17      ],
       [ 0.095     ,  0.0942    ,  0.0958    ,  0.0942    ,  0.0968    ,
         0.0956    ,  0.099     ,  0.0936    ,  0.0998    ,  0.0974    ],
       [ 0.0613    ,  0.0601    ,  0.0609    ,  0.0608    ,  0.0593    ,
         0.0611    ,  0.0604    ,  0.0596    ,  0.062     ,  0.0594    ],
       [ 0.04686667,  0.04773333,  0.04746667,  0.04693333,  0.04713333,
         0.04633333,  0.04686667,  0.04813333,  0.04713333,  0.04606667],
       [ 0.03955   ,  0.039     ,  0.03905   ,  0.03965   ,  0.0394    ,
         0.0382    ,  0.03795   ,  0.03945   ,  0.04025   ,  0.0402    ],
       [ 0.2845    ,  0.2855    ,  0.292     ,  0.286     ,  0.286     ,
         0.294     ,  0.291     ,  0.2905    ,  0.286     ,  0.284     ],
       [ 0.2084    ,  0.2276    ,  0.2198    ,  0.2152    ,  0.2136    ,
         0.2146    ,  0.2158    ,  0.2216    ,  0.2106    ,  0.2098    ],
       [ 0.1652    ,  0.1632    ,  0.1604    ,  0.165     ,  0.1652    ,
         0.1686    ,  0.166     ,  0.1622    ,  0.1624    ,  0.1663    ],
       [ 0.1318    ,  0.13146667,  0.13246667,  0.1332    ,  0.13333333,
         0.1352    ,  0.1322    ,  0.1328    ,  0.1334    ,  0.1356    ],
       [ 0.1177    ,  0.11825   ,  0.1199    ,  0.11875   ,  0.1183    ,
         0.1135    ,  0.11705   ,  0.11885   ,  0.11875   ,  0.11865   ]])), ('microarray', array([[ 0.48902597,  0.48948052,  0.48922078,  0.51785714,  0.51282468,
         0.51279221,  0.51422078,  0.51626623,  0.48928571,  0.48912338],
       [ 0.61      ,  0.54333333,  0.6       ,  0.57      ,  0.6       ,
         0.62      ,  0.62333333,  0.61666667,  0.56333333,  0.6       ],
       [ 0.5032967 ,  0.46703297,  0.51813187,  0.48956044,  0.4532967 ,
         0.53241758,  0.49615385,  0.5032967 ,  0.47582418,  0.51923077],
       [ 0.41441799,  0.42804233,  0.42791005,  0.43201058,  0.43121693,
         0.41997354,  0.42089947,  0.42037037,  0.43915344,  0.41058201],
       [ 0.50574913,  0.51347271,  0.48426249,  0.50342625,  0.50598142,
         0.50133566,  0.51747967,  0.52015099,  0.51074332,  0.5087108 ],
       [ 0.51042208,  0.51814935,  0.49675325,  0.5088961 ,  0.50551948,
         0.50720779,  0.51633117,  0.50522727,  0.51431818,  0.50558442],
       [ 0.45666667,  0.51333333,  0.48666667,  0.60666667,  0.53666667,
         0.49333333,  0.48333333,  0.46      ,  0.46666667,  0.56333333],
       [ 0.51703297,  0.52582418,  0.48956044,  0.48956044,  0.51703297,
         0.51813187,  0.56153846,  0.51098901,  0.51153846,  0.58406593],
       [ 0.5542328 ,  0.4962963 ,  0.53968254,  0.51097884,  0.49219577,
         0.49986772,  0.51018519,  0.52142857,  0.51402116,  0.5037037 ],
       [ 0.45592334,  0.4728223 ,  0.44599303,  0.43885017,  0.47711963,
         0.44860627,  0.4771777 ,  0.48222997,  0.45551684,  0.48437863],
       [ 0.48418831,  0.47295455,  0.51262987,  0.50214286,  0.48162338,
         0.48724026,  0.4800974 ,  0.50350649,  0.46428571,  0.49824675]])), ('vote', array([[ 0.38615222,  0.38588795,  0.38678647,  0.38646934,  0.3859408 ,
         0.38657505,  0.38636364,  0.38615222,  0.38636364,  0.38615222],
       [ 0.075     ,  0.065     ,  0.07      ,  0.065     ,  0.07      ,
         0.07      ,  0.045     ,  0.045     ,  0.07      ,  0.07      ],
       [ 0.11909091,  0.10909091,  0.11090909,  0.11181818,  0.11090909,
         0.10090909,  0.08272727,  0.10181818,  0.08363636,  0.11090909],
       [ 0.08290043,  0.07337662,  0.08354978,  0.08311688,  0.07857143,
         0.08311688,  0.0961039 ,  0.08354978,  0.08290043,  0.07900433],
       [ 0.07083333,  0.07045455,  0.07054924,  0.07026515,  0.07045455,
         0.07083333,  0.07689394,  0.07083333,  0.07111742,  0.07026515],
       [ 0.07811839,  0.08255814,  0.07838266,  0.07832981,  0.07362579,
         0.08255814,  0.07827696,  0.07817125,  0.08736786,  0.0737315 ],
       [ 0.16      ,  0.16      ,  0.145     ,  0.115     ,  0.1       ,
         0.085     ,  0.185     ,  0.125     ,  0.135     ,  0.185     ],
       [ 0.07272727,  0.06545455,  0.04636364,  0.03818182,  0.06545455,
         0.06454545,  0.07272727,  0.03636364,  0.05454545,  0.04545455],
       [ 0.08290043,  0.05995671,  0.06883117,  0.07835498,  0.0508658 ,
         0.06515152,  0.05562771,  0.08225108,  0.06904762,  0.07813853],
       [ 0.03068182,  0.02774621,  0.03399621,  0.03967803,  0.03077652,
         0.03058712,  0.03087121,  0.03977273,  0.03049242,  0.03683712],
       [ 0.05528541,  0.06649049,  0.05544397,  0.06654334,  0.05523256,
         0.06427061,  0.06432347,  0.05073996,  0.05047569,  0.06189218]]))]
>>> 
